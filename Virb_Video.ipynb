{
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sail] *",
   "language": "python",
   "name": "conda-env-sail-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "timestamp": "2020-12-19T22:40:14.950833-08:00"
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virb Video\n",
    "\n",
    "The goal is to be able to automatically process video from \n",
    "\n",
    "- Read the gyro/accel/mag data from the FitFile\n",
    "- Figure out timing.  Is the data synched, or really async\n",
    "- Estimate rotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "# These are libraries written for RaceAnalysis\n",
    "from global_variables import G\n",
    "from nbutils import display_markdown, display\n",
    "\n",
    "G.init_seattle(logging_level=\"INFO\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import race_logs\n",
    "import process as p\n",
    "import analysis as a\n",
    "import chart as c\n",
    "\n",
    "# This is the python-fitparse library\n",
    "from fitparse import FitFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a smallish fit file.  Note, reading FIT file with these tools is *SLOW* (10s of seconds or more).\n",
    "# This may not be a problem, since we are reading the file in order to process video, which is slower still.\n",
    "# But consider pre-processing and the serializing as a pandas file.\n",
    "\n",
    "# ff = FitFile('Data/Virb360Fit/2020-04-09-21-41-03.fit')\n",
    "# ff = FitFile('/Volumes/Big/Virb/GMetrix/2020-07-11-09-27-15.fit')\n",
    "# ff = FitFile('Data/Virb360Fit/2020-07-11-09-27-15.fit')\n",
    "\n",
    "# Short video from my backyard\n",
    "ff = FitFile('Data/Virb360Fit/2020-08-30-17-24-00.fit')\n",
    "\n",
    "recording = dict(fitfile = '/Users/viola/Python/sailing/Data/Virb360Fit/2020-09-06-16-48-20.fit',\n",
    "                 video_file_name = 'V0920368.MP4',\n",
    "                 description = 'rotate 180 to right yaw, rotate 180 to right yaw, pause, wiggle in yaw, rotate left 360 in yaw, fast right 360 yaw, roll left 90 degrees, pitch up and then pitch down (several times), roll back, returning to original position')\n",
    "\n",
    "ff = FitFile(recording['fitfile'])\n",
    "\n",
    "fitfile = ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a single message\n",
    "\n",
    "messages = it.islice(ff.get_messages(), 0, 5, None)\n",
    "msg = next(messages)\n",
    "print(repr(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the various operations available on a message.\n",
    "\n",
    "def display_msg_details(msg):\n",
    "    display_markdown(\"**`mesg_num` refers to the FIT file global schema**\")\n",
    "    print(msg.mesg_num)\n",
    "    display_markdown(\"**`as_dict()` The reference to the raw data is likely helpful, and very verbose**\")\n",
    "    print(msg.as_dict())\n",
    "    display_markdown(\"**`def_mesg` Every data message has an associated definition message.**\")\n",
    "    print(msg.def_mesg)\n",
    "    display_markdown(\"**`fields` The fields are defined in the definition message, along with info on conversions.**\")\n",
    "    print(msg.fields)\n",
    "    display_markdown(\"**`get_values()`: the values in the record...  converted when possible.**\")\n",
    "    print(msg.get_values())\n",
    "    display_markdown(\"**`header`**\")\n",
    "    print(msg.header)\n",
    "    display_markdown(\"**`name`: more like the type of the data message.**\")\n",
    "    print(msg.name)\n",
    "    display_markdown(\"**`type`: either data or definition.**\")\n",
    "    print(msg.type)\n",
    "    \n",
    "display_msg_details(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the types of messages and keep one of each.\n",
    "\n",
    "msg_dict = {}\n",
    "for i, m in enumerate(it.islice(ff.get_messages(), 0, 50000, None)):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    msg_dict[m.name] = m\n",
    "\n",
    "display(list(msg_dict.keys()))\n",
    "message_types = \"\"\n",
    "for k, msg in msg_dict.items():\n",
    "    message_types += f\"- **{k}**\\n   - {repr(msg)}\\n\"\n",
    "    \n",
    "display_markdown(message_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some messages with time stamps\n",
    "\n",
    "messages = it.islice(ff.get_messages(), 0, 10, None)\n",
    "\n",
    "def message_time(msg_values):\n",
    "    \"\"\"\n",
    "    Given message values, return the message timestamp, and if available the fulltime,\n",
    "    which is the time plus offset in milliseconds.\n",
    "    \"\"\"\n",
    "    ts = msg_values.get('timestamp', None)\n",
    "    ts_ms = msg_values.get('timestamp_ms', None)\n",
    "    fulltime = None\n",
    "    if ts is not None:\n",
    "        fulltime = float(ts)\n",
    "        if ts_ms is not None:\n",
    "            fulltime = ts + ts_ms/1000.0\n",
    "    return ts, fulltime\n",
    "\n",
    "\n",
    "def display_messages(messages):\n",
    "    for i, msg in enumerate(messages):\n",
    "        vals = msg.get_values()\n",
    "        ts, ft = message_time(vals)\n",
    "        if ts is None:\n",
    "            ts = 0\n",
    "            ft = 0.0\n",
    "        print(f\"# {i} TS: {ts:5d} FT: {ft:5.2f} -------------\")\n",
    "        print(repr(msg))\n",
    "\n",
    "display_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamps are in seconds (most likely to save file space), finer time resolution is encoded \n",
    "# in the message. \n",
    "\n",
    "# Note the messages are **NOT** in timestamp order!!!\n",
    "\n",
    "messages = it.islice(ff.get_messages(), 0, 50, None)\n",
    "\n",
    "# Note, the messages are *NOT* in monotonic order!  Why?\n",
    "def print_message_times(messages):\n",
    "    for i, msg in enumerate(messages):\n",
    "        vals = msg.get_values()\n",
    "        ts, ft = message_time(vals)\n",
    "        if ts is None:\n",
    "            ts, ft = 0, 0.0\n",
    "        print(f\"{i:3d}, {ts:5d}, {ft:7.2f} {msg.name}\")\n",
    "    return msg\n",
    "        \n",
    "print_message_times(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barometer data is very regular\n",
    "messages = it.islice(ff.get_messages('barometer_data'), 0, 10000, 10)\n",
    "\n",
    "msg = print_message_times(messages)\n",
    "\n",
    "display_markdown(\"The data in the baro message contains many samples at different offsets.\")\n",
    "display(msg.get_values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent messgaes have the same timestamp.  Time is encoded in ms\n",
    "# Any given message type appears to be in order.  \n",
    "\n",
    "display_markdown(\"Every message.\")\n",
    "messages = it.islice(ff.get_messages('gps_metadata'), 0, 100, 1)\n",
    "print_message_times(messages)\n",
    "\n",
    "display_markdown(\"Every 100th message.\")\n",
    "messages = it.islice(ff.get_messages('gps_metadata'), 0, 1000, 100)\n",
    "print_message_times(messages)\n",
    "\n",
    "display_markdown(\"Notice the slight drift in time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = msg_dict['gps_metadata']\n",
    "print(msg)\n",
    "\n",
    "def extract_flat(messages, fields):\n",
    "    rows = []\n",
    "    for i, msg in enumerate(messages):\n",
    "        vals = msg.get_values()\n",
    "        ts_sec = vals.get('timestamp', 0)\n",
    "        ts_ms = vals.get('timestamp_ms', 0)\n",
    "        ts = ts_sec + ts_ms / 1000.0\n",
    "        row = dict(ts = ts)\n",
    "        for key in fields:\n",
    "            row[key] = vals.get(key, None)\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "messages = it.islice(ff.get_messages('gps_metadata'), 0, 3000, 1)\n",
    "\n",
    "gps_fields = ['timestamp', 'position_lat', 'position_long', 'enhanced_altitude',\n",
    "              'enhanced_speed', 'utc_timestamp', 'timestamp_ms', 'heading', 'velocity']\n",
    "\n",
    "gps_df = extract_flat(messages, gps_fields)\n",
    "\n",
    "def extract_multitime_measurements(messages, fields):\n",
    "    \"\"\"\n",
    "    A multitime message, has many measurements embedded in a single messages (for\n",
    "    efficiency).  The message has a timestamp in two parts, seconds and milliseconds.\n",
    "    Each measurement additional has a offset from that in ms.\n",
    "\n",
    "    Additionally a multitime message may have multiple measurements (gyro and accel have\n",
    "    3: X, Y, and Z).\n",
    "\n",
    "       - <DataMessage: gyroscope_data (#164) -- local mesg: #14, fields: [timestamp: 194, sample_time_offset: (0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, None, None, None, None, None), gyro_x: (32808, 32813, 32817, 32823, 32825, 32826, 32818, 32812, 32809, 32801, 32802, 32805, 32807, 32804, 32800, 32799, 32797, 32766, 32686, 32926, 32909, 32708, 32891, 32825, 32776, None, None, None, None, None), gyro_y: (32764, 32762, 32764, 32763, 32766, 32770, 32771, 32775, 32777, 32777, 32776, 32779, 32782, 32782, 32785, 32786, 32786, 32789, 32811, 32772, 32789, 32788, 32791, 32794, 32781, None, None, None, None, None), gyro_z: (32697, 32697, 32699, 32699, 32701, 32701, 32701, 32701, 32698, 32698, 32699, 32699, 32699, 32698, 32697, 32694, 32702, 32713, 32423, 32487, 32741, 32691, 32693, 32693, 32693, None, None, None, None, None), timestamp_ms: 239]>\n",
    "       - <DataMessage: accelerometer_data (#165) -- local mesg: #15, fields: [timestamp: 194, sample_time_offset: (0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, None, None, None, None, None), accel_x: (32724, 32728, 32730, 32720, 32730, 32728, 32726, 32737, 32739, 32733, 32734, 32735, 32734, 32736, 32737, 32752, 32650, 32737, 32810, 32735, 32736, 32728, 32773, 32742, 32752, None, None, None, None, None), accel_y: (32786, 32794, 32791, 32787, 32778, 32774, 32786, 32776, 32780, 32790, 32790, 32788, 32780, 32778, 32774, 32831, 32282, 32642, 33045, 32374, 33018, 32811, 32637, 32872, 32786, None, None, None, None, None), accel_z: (30665, 30666, 30662, 30655, 30664, 30660, 30659, 30669, 30665, 30663, 30666, 30660, 30661, 30669, 30674, 30671, 30685, 30713, 30695, 30752, 30594, 30652, 30712, 30656, 30685, None, None, None, None, None), timestamp_ms: 239]>\n",
    "    \"\"\"\n",
    "    columns = collections.defaultdict(list)\n",
    "    for i, msg in enumerate(messages):\n",
    "        vals = msg.get_values()\n",
    "        ts_sec = vals.get('timestamp', 0)\n",
    "        ts_ms = vals.get('timestamp_ms', 0)\n",
    "        ts = ts_sec + ts_ms / 1000.0\n",
    "        offsets = [dt for dt in vals.get('sample_time_offset') if dt is not None]\n",
    "        columns['ts'] += [ts + dt/1000.0 for dt in offsets]\n",
    "        columns['sample_time_offset'] += [dt for dt in offsets]\n",
    "        columns['timestamp'] += [ts_sec for dt in offsets]\n",
    "        columns['timestamp_ms'] += [ts_ms for dt in offsets]        \n",
    "        for key in fields:\n",
    "            sensor_values = [v for v, dt in zip(vals.get(key), offsets)]\n",
    "            columns[key] += sensor_values\n",
    "    return pd.DataFrame(data=columns)\n",
    "\n",
    "messages = it.islice(ff.get_messages('barometer_data'), 0, 300, 1)\n",
    "baro_fields = ['baro_pres']\n",
    "baro_df = extract_multitime_measurements(messages, baro_fields)\n",
    "\n",
    "\n",
    "def virb_video_segments(messages):\n",
    "    \"\"\"\n",
    "    A single FIT file often refers to multiple video files (each about 30 mins).  The\n",
    "    start and end times of these segments is signaled by start and end messages.\n",
    "\n",
    "    Returns a list of start/end times.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    current = [None, None]\n",
    "    for msg in messages:\n",
    "        if msg.name == 'camera_event':\n",
    "            vals = msg.get_values()\n",
    "            if vals.get('camera_event_type', None) == 'video_start':\n",
    "                _, current[0] = message_time(vals)\n",
    "            if vals.get('camera_event_type', None) == 'video_end':\n",
    "                _, current[1] = message_time(vals)\n",
    "                segments.append(current)\n",
    "                current = [None, None]\n",
    "    return segments\n",
    "\n",
    "\n",
    "def three_d_sensor_calibrations(messages, sensor_type):\n",
    "    \"\"\"\n",
    "    Extract the sequence of calibration messages from the file.  Note, currently designed\n",
    "    for gyro and accel.\n",
    "\n",
    "    Example:\n",
    "    \n",
    "     {'timestamp': 200,\n",
    "      'gyro_cal_factor': 5,\n",
    "      'calibration_divisor': 82,\n",
    "      'level_shift': 32768,\n",
    "      'offset_cal': (35, 13, -70),\n",
    "      'orientation_matrix': (-1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0),\n",
    "      'sensor_type': 'gyroscope'}]\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for msg in messages:\n",
    "        if msg.name == 'three_d_sensor_calibration':\n",
    "            vals = msg.get_values()\n",
    "            if sensor_type == vals.get('sensor_type', None):\n",
    "                res.append(vals)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calibrate_sensors(df, calibrations, fields):\n",
    "    \"\"\"\n",
    "    Convert the sensor measurements from raw form into more meaningful units.  Typically\n",
    "    converts from an unsigned int16(?) to signed float.  Includes bias offsets (this is\n",
    "    really the calibration bit, the rest is unit conversion).\n",
    "\n",
    "    Works for gyro and accel, which are measured in triples (x, y, z).\n",
    "    \"\"\"\n",
    "    for cal1, cal2 in pairwise_longest(calibrations):\n",
    "        if cal2 is None:\n",
    "            row_selector = df.ts > cal1['timestamp']\n",
    "        else:\n",
    "            row_selector = (df.ts > cal1['timestamp']) & (df.ts <= cal2['timestamp'])\n",
    "        \n",
    "        for i, field in enumerate(fields):\n",
    "            # Iterate over each of the field (typically x, y, z).\n",
    "            \n",
    "            # Shift, typically to make it signed.\n",
    "            df.loc[row_selector, field] -= cal1['level_shift']\n",
    "            # Include bias offset \n",
    "            df.loc[row_selector, field] -= cal1['offset_cal'][i]\n",
    "            # These could have been combined, but we seems to prefer INTS.\n",
    "            df.loc[row_selector, field] *= cal_factor(cal1)\n",
    "            df.loc[row_selector, field] /= cal1['calibration_divisor']\n",
    "\n",
    "\n",
    "def fitfile_messages(fitfile, msg_name=None, msg_slice=slice(None, None, None)):\n",
    "    \"Extract the set of messages which match msg_name and msg_slice.\"\n",
    "    for msg in it.islice(fitfile.get_messages(), msg_slice.start, msg_slice.stop, msg_slice.step):\n",
    "        if msg_name is None or msg.name == msg_name:\n",
    "            yield msg\n",
    "\n",
    "\n",
    "def pairwise_longest(stuff):\n",
    "    \"Returns a list of sequential pairs, with the last having NULL as the second element.\"\n",
    "    one, two = it.tee(stuff)\n",
    "    next(two)\n",
    "    return it.zip_longest(one, two)\n",
    "\n",
    "\n",
    "def cal_factor(calibration_record):\n",
    "    \"Abstract the extraction of the cal factor for two types of messages: gyro and accel.\"\n",
    "    if 'gyro_cal_factor' in calibration_record:\n",
    "        return calibration_record['gyro_cal_factor']\n",
    "    elif 'accel_cal_factor' in calibration_record:\n",
    "        return calibration_record['accel_cal_factor']\n",
    "    else:\n",
    "        raise Exception(\"cal_factor missing from {calibration_record}\")\n",
    "\n",
    "\n",
    "def gyro_process(fitfile, msg_slice=slice(None, None, None)):\n",
    "    return imu_process(fitfile, \"gyro_x gyro_y gyro_z\".split(), 'gyroscope')\n",
    "\n",
    "\n",
    "def accel_process(fitfile, msg_slice=slice(None, None, None)):\n",
    "    return imu_process(fitfile, \"accel_x accel_y accel_z\".split(), 'accelerometer')\n",
    "\n",
    "\n",
    "def imu_process(fitfile, fields, sensor_name, msg_slice=slice(None, None, None)):\n",
    "    \"\"\"\n",
    "    Extract IMU data and convert to meaningful units.  Their are two types of IMU\n",
    "    messages, GYROSCOPE and ACCELEROMETER, stored in two different messages (though there\n",
    "    appears to be a single sensor, so all messages are timestamped with the same times).\n",
    "    \"\"\"\n",
    "\n",
    "    if True:  # test\n",
    "        fitfile = ff\n",
    "        msg_slice = slice(None, None, None)\n",
    "        sensor_name = \"accelerometer\"\n",
    "        fields = \"accel_x accel_y accel_z\".split()\n",
    "        \n",
    "    calibrations = three_d_sensor_calibrations(fitfile_messages(fitfile, msg_slice=msg_slice), sensor_name)\n",
    "\n",
    "    # A large FIT file can be broken into multiple video segments.  Extract and label these.\n",
    "    segment_times = virb_video_segments(fitfile_messages(fitfile, msg_slice=msg_slice))\n",
    "\n",
    "    df = extract_multitime_measurements(fitfile_messages(fitfile, sensor_name+'_data', msg_slice=msg_slice), fields)\n",
    "    df['diff'] = df.ts.diff()\n",
    "    calibrate_sensors(df, calibrations, fields)\n",
    "    video_segments(df, segment_times, fields)\n",
    "    plot_sensors(df, fields)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def video_segments(df, segment_times, fields):\n",
    "    df['segment'] = 0\n",
    "    df['ts_segment'] = df.ts \n",
    "    for segment_number, (ts_start, ts_end) in enumerate(segment_times):\n",
    "        row_selector = (df.ts > ts_start) & (df.ts <= ts_end)\n",
    "        df.loc[row_selector, 'ts_segment'] = df.ts_segment - ts_start\n",
    "        df.loc[row_selector, 'segment'] = segment_number + 1\n",
    "\n",
    "\n",
    "def plot_sensors(df, fields, fignum=None):\n",
    "    fig = plt.figure(num=fignum)\n",
    "    fig.clf()\n",
    "    ax = fig.add_subplot(111)    \n",
    "    ts_start = df[df.segment >= 0].ts.min()\n",
    "\n",
    "    max_val = 0\n",
    "    for field, color in zip(fields, \"r g b\".split()):    \n",
    "        ax.plot(df.ts-ts_start, df[field], color=color)\n",
    "        max_val = max(max_val, df[field].max())\n",
    "    segment_count = df.segment.max()\n",
    "    ax.plot(df.ts-ts_start, max_val*df.segment/segment_count, color='orange')\n",
    "    ax.legend(fields + ['video'])\n",
    "\n",
    "\n",
    "################################################################\n",
    "\n",
    "gdf = gyro_process(ff)\n",
    "adf = accel_process(ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = msg_dict['gps_metadata']\n",
    "\n",
    "display(repr(msg))\n",
    "display(msg.get_values())\n",
    "\n",
    "display(msg.as_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(m))\n",
    "m.mesg_type\n",
    "m.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ff.get_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = list(it.islice(ff.get_messages('camera_event'), 0, 2, None))\n",
    "\n",
    "dfs = []\n",
    "rows = [m.get_values() for m in messages]\n",
    "dfs.append(pd.DataFrame(rows))\n",
    "\n",
    "df = dfs[0]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = list(it.islice(ff.get_messages('gyroscope_data'), 0, 2, None))\n",
    "\n",
    "dfs = []\n",
    "rows = [m.get_values() for m in messages]\n",
    "dfs.append(pd.DataFrame(rows))\n",
    "\n",
    "df = dfs[0]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}