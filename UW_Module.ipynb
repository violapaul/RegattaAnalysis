{
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sail] *",
   "language": "python",
   "name": "conda-env-sail-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "timestamp": "2020-06-12T21:57:50.709355-07:00"
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UW Live Ocean Data\n",
    "\n",
    "Found a potentially great resource at UW:\n",
    "\n",
    "http://faculty.washington.edu/pmacc/LO/LiveOcean.html\n",
    "\n",
    "> LiveOcean works a lot like the weather forecast models that we all rely on every day. It takes in information about the state of the ocean, atmosphere and rivers on a given day, and then uses the laws of physics (and a large computer) to predict how the state of the ocean in our region will change over the next few days. The things that the model predicts are currents, salinity, temperature, chemical concentrations of nitrate, oxygen, carbon, and biological fields like phytoplankton, zooplankton, and organic particles. It does this in three dimensions, and allowing continuous variation over the full 72 hour forecast it makes every day.\n",
    "\n",
    "- [How the Model Works](http://faculty.washington.edu/pmacc/LO/how_it_works.html)\n",
    "\n",
    "> The model framework we use is called the Regional Ocean Modeling System (ROMS) which is a large, flexible computer code that is used by coastal and estuarine oceanographers around the world to simulate different regions. It is known to have excellent numerical properties, such as low numerical diffusion, many choices for turbulence parameterization and open boundary conditions, built-in biogeochemical models, and a large, active user community. We have been using ROMS for realistic simulations in the region for research projects for the past decade and have found it to be a robust tool.\n",
    "\n",
    "Its based on the [ROMS Finite Element Model](https://www.myroms.org/)\n",
    "\n",
    "- [Awesome Accessible Description of Tides](http://faculty.washington.edu/pmacc/LO/tides_background.html)\n",
    "\n",
    "## Data From Parker MacCready\n",
    "\n",
    "Exchanged emails with Prof. MacCready and he pointed me toward his daily model outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os\n",
    "import datetime\n",
    "import itertools as it\n",
    "\n",
    "import arrow\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy.ma as ma\n",
    "from numba import jit\n",
    "\n",
    "import netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are libraries written for RegattaAnalysis\n",
    "from global_variables import G  # global variables\n",
    "import race_logs                # load data from races\n",
    "import chart\n",
    "import utils\n",
    "import process as p\n",
    "from utils import DictClass\n",
    "\n",
    "import metadata\n",
    "\n",
    "import nbutils\n",
    "from nbutils import display_markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.init_seattle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NetCDF file containing the UW Live Ocean current model can be downloaded as follows.\n",
    "\n",
    "LIVE_OCEAN_BASE = \"https://pm2.blob.core.windows.net\"\n",
    "LIVE_OCEAN_FILE = \"ocean_surface.nc\"\n",
    "LIVE_OCEAN_DATA_DIRECTORY = \"/Users/viola/BigData\"\n",
    "\n",
    "def live_ocean_path(date_string):\n",
    "    \"Path to the live ocean file for this date.\"\n",
    "    adt = arrow.get(date_string)\n",
    "    result_filename = adt.format(\"YYYY-MM-DD\") + \"_ocean_surface.nc\"\n",
    "    return os.path.join(LIVE_OCEAN_DATA_DIRECTORY, result_filename)\n",
    "\n",
    "def fetch_live_ocean_model(date_string):\n",
    "    \"\"\"\n",
    "    Fetch the UW Live Ocean current model.  If the file has already been downloaded, then\n",
    "    return the path.  If not, beging an asynchronous download and return False.\n",
    "    \"\"\"\n",
    "    time = utils.time_from_string(date_string)\n",
    "    path = live_ocean_path(date_string)\n",
    "    if os.path.exists(path):\n",
    "        G.logger.info(f\"File {path} already downloaded. Skipping.\")\n",
    "        return DictClass(path=path, date=date_string)\n",
    "    else:\n",
    "        # Construct the full URL \n",
    "        directory = \"f\" + utils.time_to_string(time, \"YYYYMMDD\")\n",
    "        url = f\"{LIVE_OCEAN_BASE}/{directory}/{LIVE_OCEAN_FILE}\"\n",
    "        download_path = path + \".incomplete\"\n",
    "        log_file = \"/tmp/wget-log\"\n",
    "        command = f\"(wget {url} -O {download_path} -c -o {log_file}; mv {download_path} {path})&\"\n",
    "        print(command)\n",
    "        utils.run_system_command(command)\n",
    "        display(f\"Downloading model to {path}.  Check {log_file}.  Incomplete results here: {download_path}.\")\n",
    "        return False\n",
    "\n",
    "def read_live_ocean_model(date):\n",
    "    \"\"\"\n",
    "    Read the UW live ocean model for a given date.\n",
    "\n",
    "    Note this is the date when the model was generated, and includes predicitions for\n",
    "    subsequent times/dates.  When looking for predictions, it may be necessary to fetch\n",
    "    the most recent model and then query the future.\n",
    "    \"\"\"\n",
    "    model = fetch_live_ocean_model(date)\n",
    "    if model is None:\n",
    "        display(\"Wait and try again soon!\")\n",
    "        return None\n",
    "    model.netcdf = netCDF4.Dataset(model.path)\n",
    "\n",
    "    model.current_n = model.netcdf.variables['v'][:, :, :]\n",
    "    model.current_e = model.netcdf.variables['u'][:, :, :]\n",
    "\n",
    "    model.wind_n = model.netcdf.variables['Vwind'][:, :, :]\n",
    "    model.wind_e = model.netcdf.variables['Uwind'][:, :, :]\n",
    "\n",
    "    model.ocean_time = model.netcdf.variables['ocean_time'][:]\n",
    "    model.lon_rho = model.netcdf.variables['lon_rho'][:]\n",
    "    model.lat_rho = model.netcdf.variables['lat_rho'][:]\n",
    "    model.east, model.north = G.MAP(model.lon_rho, model.lat_rho)  # Works great with numpy masked arrays.\n",
    "    return model\n",
    "\n",
    "def find_times(uw_model, start, finish):\n",
    "    tstart = utils.time_from_string(start)\n",
    "    tfinish = utils.time_from_string(finish)\n",
    "    time_indices = []\n",
    "    for i, tstamp in enumerate(uw_model.ocean_time):\n",
    "        t = utils.time_from_timestamp(tstamp)\n",
    "        if utils.time_after(tstart, t) and utils.time_after(t, tfinish):\n",
    "            time_indices.append(i)\n",
    "    if len(time_indices) == 0:\n",
    "        return time_indices\n",
    "    if time_indices[0] > 0:\n",
    "        time_indices = [time_indices[0]-1] + time_indices\n",
    "    if time_indices[-1] < len(uw_model.ocean_time)-1:\n",
    "        time_indices = time_indices + [time_indices[-1]+1]\n",
    "    return time_indices, [utils.time_from_timestamp(uw_model.ocean_time[t]) for t in time_indices]\n",
    "\n",
    "\n",
    "def region_from_marks(marks, lat_border=0.2, lon_border=0.3):\n",
    "    pos = [G.STYC_RACE_MARKS[m] for m in marks]\n",
    "    lats = [p.lat for p in pos]\n",
    "    lons = [p.lon for p in pos]    \n",
    "    lat_max, lat_min = chart.max_min_with_border(np.array(lats), lat_border)\n",
    "    lon_max, lon_min = chart.max_min_with_border(np.array(lons), lon_border)\n",
    "    return DictClass(lat_max=lat_max, lat_min=lat_min,\n",
    "                     lon_max=lon_max, lon_min=lon_min)\n",
    "\n",
    "def lor(a, *b):\n",
    "    \"Numpy logical-or of all arguments.\" \n",
    "    res = a\n",
    "    for e in b:\n",
    "        res = np.logical_or(res, e)\n",
    "    return res\n",
    "\n",
    "def land(a, *b):\n",
    "    \"Numpy logical-or of all arguments.\" \n",
    "    res = a\n",
    "    for e in b:\n",
    "        res = np.logical_and(res, e)\n",
    "    return res\n",
    "\n",
    "def display_currents(uw_model, region, time_index):\n",
    "    \"\"\"\n",
    "    Draw a chart overlayed with the UW live ocean current predictions.\n",
    "    \"\"\"\n",
    "    ch = chart.create_chart(region)\n",
    "    ch.fig = plt.figure(figsize=(8, 10))\n",
    "    ch.ax = ch.fig.add_subplot(111)   \n",
    "    ch = chart.draw_chart(ch, ch.ax)\n",
    "    return draw_current(ch, uw_model, time_index)\n",
    "\n",
    "\n",
    "def draw_current(ch, uw_model, time_index):\n",
    "\n",
    "    # Current is in meters/sec. And we typically think in knots.  1 m/s is 2 kts.  If you\n",
    "    # scale by 1000 then a 1kt current is 500m.\n",
    "\n",
    "    scale = 1000\n",
    "    u = scale * uw_model.current_e[time_index, :, :]\n",
    "    v = scale * uw_model.current_n[time_index, :, :]\n",
    "\n",
    "    dt = utils.time_from_timestamp(uw_model.ocean_time[time_index])\n",
    "    ch.datetime = dt\n",
    "\n",
    "    # Note, for masked arrays mask is TRUE for undefined.\n",
    "    lat_mask = lor(uw_model.lat_rho > ch.lat_max, uw_model.lat_rho < ch.lat_min)\n",
    "    lon_mask = lor(uw_model.lon_rho > ch.lon_max, uw_model.lon_rho < ch.lon_min)\n",
    "    ll_mask = lor(lat_mask, lon_mask)\n",
    "\n",
    "    mask = np.logical_not(lor(ll_mask, u.mask, v.mask))\n",
    "\n",
    "    one_knot = (1/G.MS_2_KNOTS) * scale/np.sqrt(2)\n",
    "    ch.ax.arrow(2700, 737, one_knot, one_knot, head_width=100, length_includes_head=True, color='red')\n",
    "\n",
    "    ch.ax.quiver(uw_model.east[mask], uw_model.north[mask], u[mask], v[mask], \n",
    "                 angles='xy', scale_units='xy', scale=1, color='blue')\n",
    "    \n",
    "    ch.ax.set_title(uw_model.date + \" : \" + utils.time_to_string(dt))\n",
    "    return ch\n",
    "\n",
    "def plot_marks(ch, marks):\n",
    "    \"Plot the STYC marks identified by name.\"\n",
    "    pos = [G.STYC_RACE_MARKS[m.casefold()] for m in marks]\n",
    "    lats = np.array([p.lat for p in pos])\n",
    "    lons = np.array([p.lon for p in pos])\n",
    "    marks = np.vstack(G.MAP(lons, lats)).T \n",
    "    # Add red x's to the chart ABOVE, at the location of the marks\n",
    "    ch.ax.scatter(marks[:, 0], marks[:, 1], color='red', marker='x')\n",
    "\n",
    "def save_chart(ch, directory=\"\"):\n",
    "    \"Save a current chart to a file, using time as filename.\"\n",
    "    filename = f\"current_{utils.time_to_string(ch.datetime)}.pdf\"\n",
    "    path = os.path.join(directory, filename)\n",
    "    ch.fig.savefig(path, orientation='portrait')\n",
    "\n",
    "def create_charts(date, start_time, end_time, region, marks=None):\n",
    "    \"\"\"\n",
    "    Create a set of current charts from the UW Live Ocean data, for a given day that span\n",
    "    from the start time to the finish.\n",
    "\n",
    "    Times are local times, 24 hours.\n",
    "\n",
    "    Models are generated daily, and include predicitions for for the next 2 days. If looking\n",
    "    for predictions on a future date, you must fetch the most recent model.\n",
    "    \"\"\"\n",
    "\n",
    "    if fetch_live_ocean_model(date):\n",
    "        uw_model = read_live_ocean_model(date)\n",
    "        time_indices, times  = find_times(uw_model, f\"{date} {start_time}\", f\"{date} {end_time}\")\n",
    "        ch_list = [display_currents(uw_model, region, t) for t in time_indices]\n",
    "        for ch in ch_list:\n",
    "            if marks is not None:\n",
    "                plot_marks(ch, marks)\n",
    "        return ch_list\n",
    "    else:\n",
    "        display(\"Wait for model file to fetch!\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def region_from_df(df, lat_border=0.2, lon_border=0.3):\n",
    "    \"\"\"\n",
    "    Extract the geographic region which covers the entire race track.  BORDER is an\n",
    "    additional margin which ensures you do not bump up against the edge when graphing.\n",
    "    \"\"\"\n",
    "    # Add just a bit of \"fudge factor\" to ensure that the extent is not too small, which\n",
    "    # triggers some corner cases.\n",
    "    fudge = (0.015, -0.015)\n",
    "\n",
    "    # TODO: since the border is applied in lat/lon separately, its is not uniform.  Same\n",
    "    # for FUDGE.\n",
    "    lat_max, lat_min = chart.max_min_with_border(df.latitude, lat_border) + fudge\n",
    "    lon_max, lon_min = chart.max_min_with_border(df.longitude, lon_border) + fudge\n",
    "\n",
    "    return DictClass(lat_max=lat_max, lat_min=lat_min,\n",
    "                     lon_max=lon_max, lon_min=lon_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_boat_currents(ch, df, dt_seconds=5, scale=1000, leeway=8, multiplier=1.1):\n",
    "    delay = 16\n",
    "    dt = dt_seconds * G.SAMPLES_PER_SECOND\n",
    "\n",
    "    ch_begin = (ch.datetime + datetime.timedelta(hours=-1)).datetime\n",
    "    ch_end = (ch.datetime + datetime.timedelta(hours=+1)).datetime\n",
    "\n",
    "    tdf = df[(df.row_times > ch_begin) &  (df.row_times < ch_end)]\n",
    "    chart.draw_track(df, ch, color='lightgrey')\n",
    "    chart.draw_track(tdf, ch, color='olive')    \n",
    "\n",
    "    mdf = tdf.iloc[:-delay:dt]\n",
    "    ddf = tdf.iloc[delay::dt]\n",
    "\n",
    "    vog_n = ddf.sog * p.north_d(ddf.cog)\n",
    "    vog_e = ddf.sog * p.east_d(ddf.cog)\n",
    "\n",
    "    thdg = mdf.hdg.copy()\n",
    "\n",
    "    port_hauled = land(mdf.awa < 0, mdf.awa > -120)\n",
    "    stbd_hauled = land(mdf.awa > 0, mdf.awa < 120)\n",
    "\n",
    "    thdg[port_hauled] = thdg[port_hauled] + leeway\n",
    "    thdg[stbd_hauled] = thdg[stbd_hauled] - leeway    \n",
    "    \n",
    "    hdg = thdg + df.variation.mean()\n",
    "\n",
    "    btv_n = multiplier * mdf.spd * p.north_d(hdg)\n",
    "    btv_e = multiplier * mdf.spd * p.east_d(hdg)\n",
    "\n",
    "    cur_n = (np.asarray(vog_n) - np.asarray(btv_n))\n",
    "    cur_e = (np.asarray(vog_e) - np.asarray(btv_e))\n",
    "\n",
    "    longitudes = np.asarray(mdf.longitude)\n",
    "    latitudes = np.asarray(mdf.latitude)\n",
    "    east, north = G.MAP(longitudes, latitudes)\n",
    "\n",
    "    ch.ax.quiver(east, north, scale/10 * btv_e, scale/10 * btv_n,\n",
    "                angles='xy', scale_units='xy', scale=1, color='orange',\n",
    "                width=0.003)\n",
    "    \n",
    "    ch.ax.quiver(east, north, scale/10 * vog_e, scale/10 * vog_n,\n",
    "                angles='xy', scale_units='xy', scale=1, color='aqua',\n",
    "                width=0.003)\n",
    "\n",
    "    \n",
    "    ch.ax.quiver(east, north, scale * cur_e, scale * cur_n,\n",
    "                angles='xy', scale_units='xy', scale=1, color='red',\n",
    "                width=0.003)\n",
    "        \n",
    "    # ch.ax.quiver(east, north, scale * btv_e, scale * btv_n,\n",
    "    #              angles='xy', scale_units='xy', scale=1, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "date = \"2020-05-09\"\n",
    "uw_model = read_live_ocean_model(date)\n",
    "df, race = race_logs.read_date(date)\n",
    "display(race.title)\n",
    "\n",
    "region = region_from_df(df, 0.2, 0.4)\n",
    "\n",
    "start_time = df.row_times.iloc[0].strftime(\"%H:%M:%S\")\n",
    "end_time = df.row_times.iloc[-1].strftime(\"%H:%M:%S\")\n",
    "\n",
    "ch = chart.plot_chart(df)\n",
    "\n",
    "time_indices, times  = find_times(uw_model, f\"{date} {start_time}\", f\"{date} {end_time}\")\n",
    "\n",
    "ch = display_currents(uw_model, region, time_indices[1]) \n",
    "show_boat_currents(ch, df, dt_seconds=90, leeway=5, multiplier=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - plot charts for a day on the water\n",
    "\n",
    "if True:\n",
    "    date = \"2020-06-12\"\n",
    "    marks = \"nmwnrwn\"\n",
    "    region = region_from_marks(marks, 0.4, 0.8)\n",
    "    start_time = \"10:00:00\"\n",
    "    end_time = \"16:00:00\"\n",
    "    # Note if the model is not downloaded will return None.  Takes 20 mins.\n",
    "    ch_list = create_charts(date, start_time, end_time, region)\n",
    "    if ch_list is not None:\n",
    "        display(\"Saving charts in /tmp\")\n",
    "        for ch in ch_list:\n",
    "            save_chart(ch, \"/tmp\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook \n",
    "\n",
    "# I was able to grab an NC file from:\n",
    "# https://pm2.blob.core.windows.net/f20200520/ocean_surface.nc\n",
    "#\n",
    "# From: Parker MacCready <p.maccready@gmail.com>\n",
    "# It has the surface currents (u,v) for all 73 hours of today's forecast on the \n",
    "# lon_rho, lat_rho grid.  New ones appear every day by around 8 AM.\n",
    "\n",
    "data_dir = \"/Users/viola/BigData\"\n",
    "model_file = \"2020-06-01_ocean_surface.nc\"\n",
    "\n",
    "ncdf_ocean = netCDF4.Dataset(os.path.join(data_dir, model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This a function cribbed from link sort of verbose but handy.\n",
    "# http://schubert.atmos.colostate.edu/~cslocum/netcdf_example.html#code\n",
    "\n",
    "def ncdump(nc_fid, verb=True):\n",
    "    '''\n",
    "    ncdump outputs dimensions, variables and their attribute information.\n",
    "    The information is similar to that of NCAR's ncdump utility.\n",
    "    ncdump requires a valid instance of Dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc_fid : netCDF4.Dataset\n",
    "        A netCDF4 dateset object\n",
    "    verb : Boolean\n",
    "        whether or not nc_attrs, nc_dims, and nc_vars are printed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nc_attrs : list\n",
    "        A Python list of the NetCDF file global attributes\n",
    "    nc_dims : list\n",
    "        A Python list of the NetCDF file dimensions\n",
    "    nc_vars : list\n",
    "        A Python list of the NetCDF file variables\n",
    "    '''\n",
    "    def print_ncattr(key):\n",
    "        \"\"\"\n",
    "        Prints the NetCDF file attributes for a given key\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        key : unicode\n",
    "            a valid netCDF4.Dataset.variables key\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"\\t\\ttype:\", repr(nc_fid.variables[key].dtype))\n",
    "            for ncattr in nc_fid.variables[key].ncattrs():\n",
    "                print('\\t\\t%s:' % ncattr, repr(nc_fid.variables[key].getncattr(ncattr)))\n",
    "        except KeyError:\n",
    "            print(\"\\t\\tWARNING: %s does not contain variable attributes\" % key)\n",
    "\n",
    "    # NetCDF global attributes\n",
    "    nc_attrs = nc_fid.ncattrs()\n",
    "    if verb:\n",
    "        print(\"NetCDF Global Attributes:\")\n",
    "        for nc_attr in nc_attrs:\n",
    "            print('\\t%s:' % nc_attr, repr(nc_fid.getncattr(nc_attr)))\n",
    "    nc_dims = [dim for dim in nc_fid.dimensions]  # list of nc dimensions\n",
    "    # Dimension shape information.\n",
    "    if verb:\n",
    "        print(\"NetCDF dimension information:\")\n",
    "        for dim in nc_dims:\n",
    "            print(\"\\tName:\", dim )\n",
    "            print(\"\\t\\tsize:\", len(nc_fid.dimensions[dim]))\n",
    "            print_ncattr(dim)\n",
    "    # Variable information.\n",
    "    nc_vars = [var for var in nc_fid.variables]  # list of nc variables\n",
    "    if verb:\n",
    "        print(\"NetCDF variable information:\")\n",
    "        for var in nc_vars:\n",
    "            if var not in nc_dims:\n",
    "                print('\\tName:', var)\n",
    "                print(\"\\t\\tdimensions:\", nc_fid.variables[var].dimensions)\n",
    "                print(\"\\t\\tsize:\", nc_fid.variables[var].size)\n",
    "                print_ncattr(var)\n",
    "    return nc_attrs, nc_dims, nc_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(seconds):\n",
    "    \"Convenience to convert ncdf times to datetimes.\"\n",
    "    epoch = datetime.datetime.utcfromtimestamp(0)\n",
    "    dt = epoch + datetime.timedelta(0, seconds)\n",
    "    return arrow.get(dt).to('US/Pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "# Let's see what is in the file (as advertized it is very similar to ncdump)\n",
    "ncdump(ncdf_ocean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetCDF is self documenting.\n",
    "\n",
    "We are specifically interested in U,V which are the current predictions in m/s (note, it does not say current, but Parker's email points this out).  \n",
    "\n",
    "We are likely also interested in Uwind and Vwind (if they turn out to be more accurate than other local predictions).  **But are these inputs to the ocean model, or outputs?** And if inputs, from what model?\n",
    "\n",
    "NetCDF is a gridded representation.  In this case the \"data\" is triple indexed\n",
    "by `('ocean_time', 'eta_rho', 'xi_rho')`.\n",
    "\n",
    "But what does this mean?  The data is on a fixed grid indexed by integers, but the **meaning** of that grid location is held in the associated variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "display_markdown(\"## Meaning of the index variables.\")\n",
    "\n",
    "for name in \"ocean_time lon_rho lat_rho\".split():\n",
    "    display_markdown(f\"### {name}\")\n",
    "    display(ncdf_ocean.variables[name])\n",
    "    display(ncdf_ocean.variables[name][:])\n",
    "\n",
    "ocean_time = ncdf_ocean.variables['ocean_time'][:]\n",
    "lon_rho = ncdf_ocean.variables['lon_rho'][:]\n",
    "lat_rho = ncdf_ocean.variables['lat_rho'][:]\n",
    "\n",
    "[to_datetime(ot) for ot in ocean_time]\n",
    "\n",
    "# Similarly we can extract the actual current data:\n",
    "\n",
    "current_n = ncdf_ocean.variables['v'][:, :, :]\n",
    "current_e = ncdf_ocean.variables['u'][:, :, :]\n",
    "wind_n = ncdf_ocean.variables['Vwind'][:, :, :]\n",
    "wind_e = ncdf_ocean.variables['Uwind'][:, :, :]\n",
    "\n",
    "im = current_n[0, :, :]\n",
    "display(im)\n",
    "display(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the array is masked. \n",
    "\n",
    "https://numpy.org/doc/stable/reference/maskedarray.generic.html\n",
    "\n",
    "And this makes sense, since the value of the current is not defined on land, etc.\"\n",
    "\n",
    "Note, `True` implies that the data is **NOT** valid.\n",
    "\n",
    "And conveniently matplotlib handles masked array directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, num=None)\n",
    "fig.tight_layout()\n",
    "ax.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is going on with this?\n",
    "\n",
    "Looking at the image, it appears to be corrupted.  Its not.  (While it is ultimately not important, you can \"see\" the map if you flip it vertically and then ignore the distortion.  Seattle is at roughly x=602, y=745.)\n",
    "\n",
    "Remember that each pixel in the image is the speed of the current at a particular time and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "i = 0\n",
    "j = 745\n",
    "k = 602\n",
    "display(f\"Northward current is: {current_n[i, j, k]}\")  # is the value at \n",
    "display(f\"time = {to_datetime(ocean_time[i]).isoformat()}\")\n",
    "display(f\"longitude = {lon_rho[j, k]}\")\n",
    "display(f\"latitude = {lat_rho[j, k]}\")\n",
    "\n",
    "display(\"Lat/Lon of Seattle is: 47.6062\u00b0 N, 122.3321\u00b0 W\")\n",
    "\n",
    "# We can convert these lat/lon coordinate to a local projection using Pyproj.  \n",
    "\n",
    "east, north = G.MAP(lon_rho, lat_rho)  # Works great with numpy masked arrays.\n",
    "\n",
    "# The result is in meters east from our center of projection.\n",
    "east"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data\n",
    "\n",
    "We now have a subtle problem, the data is not really an image.  There are parts of the map where the sampling coarse and others where it is fine (there are more pixels in some places and less others).  We can perform a quick hack to turn this into an image as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute an image, in our projected coordinates, where the value of the pixel is \n",
    "# determined by mapping the lat/lon coordinate into pixel coordinates.\n",
    "#\n",
    "# Resulting image is 2*size x 2*size.  Do not process points which are more than \n",
    "# threshold distance away in east or north.\n",
    "#\n",
    "# For any given image, there are likely to be holes.\n",
    "\n",
    "def forward_map(east, north, values, threshold, size):\n",
    "    res = np.zeros((2+size*2, 2+size*2))\n",
    "    mask = np.ones(res.shape, np.bool)\n",
    "    forward_map_helper(east, north, values.data, values.mask, res, mask, threshold, size)\n",
    "    return ma.array(data=res, mask=mask)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def forward_map_helper(east, north, values, values_mask, res, mask, threshold, size):\n",
    "    height, width = east.shape\n",
    "    for c in range(width):\n",
    "        for r in range(height):\n",
    "            if np.abs(east[r, c]) < threshold and np.abs(north[r, c]) < threshold:\n",
    "                x = int(1 + size + size * east[r, c]/threshold)\n",
    "                y = int(1 + size + -size * north[r, c]/threshold)\n",
    "                if not values_mask[r, c]:\n",
    "                    res[y, x] = values[r, c]\n",
    "                    mask[y, x] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "dist = 40000\n",
    "# First construct a higher resolution image\n",
    "res = forward_map(east, north, im, dist, 200)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(res, extent=[-dist, dist, -dist, dist])\n",
    "\n",
    "# Second a lower res image.\n",
    "res = forward_map(east, north, im, dist, 75)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(res, extent=[-dist, dist, -dist, dist])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like Seattle, but notice the holes\n",
    "\n",
    "Specifically zoom in on the higher resolution image.  The Live Ocean data is 0.5km.  When the image resolution is higher than 0.5km then there are pixels where there is no estimate.  Using a lower resolution image (second image) fills in the gaps, but it is unnecessarily coarse.\n",
    "\n",
    "Note, ultimately these images are not particularly useful.  But it does show the structure of the underlying data.\n",
    "\n",
    "We can also fill in the holes, using a blend of nearby pixels.  Note, this does a nice job **except** near the coastline, where it blurs things (it is unaware of the coast)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "def gaussian_kernel(kernel_size, sigma):\n",
    "    kernel = np.zeros((kernel_size, kernel_size))\n",
    "    middle = np.int(kernel_size/2)\n",
    "    for c in range(kernel_size):\n",
    "        for r in range(kernel_size):\n",
    "            d = np.square(c - middle) + np.square(r - middle)\n",
    "            kernel[c, r] = np.exp(-sigma * d/np.square(middle))\n",
    "    return kernel\n",
    "\n",
    "def image_fill(image, kernel_size):\n",
    "    \"Fill in missing values in image by taking a weighted blend of nearby pixels.\"\n",
    "    kernel = gaussian_kernel(kernel_size, 1.5)\n",
    "    res = np.zeros(image.shape)\n",
    "    mask = np.ones(res.shape, np.bool)\n",
    "    image_fill_helper(image.data, image.mask, res, mask, kernel)\n",
    "    return ma.array(data=res, mask=mask)\n",
    "                    \n",
    "@jit(nopython=True)\n",
    "def image_fill_helper(image, mask, res, res_mask, kernel):\n",
    "    height, width = image.shape\n",
    "    size = kernel.shape[0]\n",
    "    delta = np.int(size/2)\n",
    "    for c in range(delta+1, width-(delta+1)):\n",
    "        for r in range(delta+1, height-(delta+1)):\n",
    "            if mask[r, c]:\n",
    "                s = 0\n",
    "                w = 0\n",
    "                for dc in range(-delta, size-delta):\n",
    "                    for dr in range(-delta, size-delta):\n",
    "                        if not mask[dr+r, dc+c]:\n",
    "                            w += kernel[dr, dc]\n",
    "                            s += image[dr+r, dc+c] * kernel[dr, dc]\n",
    "                if w > 0:\n",
    "                    res[r, c] = s/w\n",
    "                    res_mask[r, c] = False\n",
    "            else:\n",
    "                res[r, c] = image[r, c]\n",
    "                res_mask[r, c] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "res = forward_map(east, north, im, dist, 1000)\n",
    "filled = image_fill(res, 13)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(filled, extent=[-dist, dist, -dist, dist])\n",
    "\n",
    "dist = 15000\n",
    "scale = 1500\n",
    "\n",
    "maske = lor(east < -dist, east > dist)\n",
    "maskn = lor(north < -dist, north > dist)\n",
    "\n",
    "for time in range(0, 1, 1):\n",
    "    u = scale * current_e[time, :, :]\n",
    "    v = scale * current_n[time, :, :]\n",
    "\n",
    "    mask = np.logical_not(lor(maske, maskn, u.mask, v.mask))\n",
    "    display(to_datetime(ocean_time[time]).isoformat())\n",
    "\n",
    "    plt.figure()\n",
    "    plt.quiver(east[mask], north[mask], u[mask], v[mask], \n",
    "               angles='xy', scale_units='xy', scale=1)\n",
    "    plt.axis('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "def example_race(date=\"2019-11-16\"):\n",
    "    dfs, races, big_df = race_logs.read_dates([date], race_trim=False)\n",
    "    display(races)\n",
    "    return dfs[0]\n",
    "\n",
    "df = example_race(\"2020-04-28\")\n",
    "model_file = \"2020-06-01_ocean_surface.nc\"\n",
    "\n",
    "ncdf_ocean = netCDF4.Dataset(os.path.join(data_dir, model_file))\n",
    "\n",
    "current_n = ncdf_ocean.variables['v'][:, :, :]\n",
    "current_e = ncdf_ocean.variables['u'][:, :, :]\n",
    "wind_n = ncdf_ocean.variables['Vwind'][:, :, :]\n",
    "wind_e = ncdf_ocean.variables['Uwind'][:, :, :]\n",
    "\n",
    "ocean_time = ncdf_ocean.variables['ocean_time'][:]\n",
    "lon_rho = ncdf_ocean.variables['lon_rho'][:]\n",
    "lat_rho = ncdf_ocean.variables['lat_rho'][:]\n",
    "\n",
    "ch = chart.plot_chart(df, border=0.7, color='red')\n",
    "\n",
    "# Note, for masked arrays mask is TRUE for undefined.\n",
    "lat_mask = lor(lat_rho > ch.lat_max, lat_rho < ch.lat_min)\n",
    "lon_mask = lor(lon_rho > ch.lon_max, lon_rho < ch.lon_min)\n",
    "ll_mask = lor(lat_mask, lon_mask)\n",
    "\n",
    "mm = np.logical_not(lor(maske, maskn))\n",
    "\n",
    "region = DictClass(lat_max=lat_rho[mm].max(), lat_min=lat_rho[mm].min(),\n",
    "                   lon_min=lon_rho[mm].min(), lon_max=lon_rho[mm].max())\n",
    "region\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "for i in [12, 13, 14]:\n",
    "    display_currents(ch, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook \n",
    "\n",
    "def show_boat_currents(ch, df, df_slice, dt_seconds=5, scale=1000, leeway=8):\n",
    "    delay = 16\n",
    "    dt = dt_seconds * G.SAMPLES_PER_SECOND\n",
    "\n",
    "    ss = slice(df_slice.start, df_slice.stop, dt)\n",
    "    dss = slice(ss.start+delay, ss.stop+delay, dt)\n",
    "    \n",
    "    mdf = df.loc[ss]\n",
    "    ddf = df.loc[dss]\n",
    "    vog_n = ddf.sog * p.north_d(ddf.cog)\n",
    "    vog_e = ddf.sog * p.east_d(ddf.cog)\n",
    "\n",
    "    thdg = mdf.hdg.copy()\n",
    "\n",
    "    port_hauled = land(mdf.awa < 0, mdf.awa > -50)\n",
    "    stbd_hauled = land(mdf.awa > 0, mdf.awa < 50)\n",
    "\n",
    "    thdg[port_hauled] = thdg[port_hauled] + leeway\n",
    "    thdg[stbd_hauled] = thdg[stbd_hauled] - leeway    \n",
    "    \n",
    "    hdg = thdg + df.variation.mean()\n",
    "\n",
    "    btv_n = mdf.spd * p.north_d(hdg)\n",
    "    btv_e = mdf.spd * p.east_d(hdg)\n",
    "\n",
    "    cur_n = (np.asarray(vog_n) - np.asarray(btv_n))\n",
    "    cur_e = (np.asarray(vog_e) - np.asarray(btv_e))\n",
    "\n",
    "    longitudes = np.asarray(mdf.longitude)\n",
    "    latitudes = np.asarray(mdf.latitude)\n",
    "    east, north = G.MAP(longitudes, latitudes)\n",
    "\n",
    "    ch.ax.quiver(east, north, scale * cur_e, scale * cur_n,\n",
    "                 angles='xy', scale_units='xy', scale=1, color='orange')\n",
    "        \n",
    "    # ch.ax.quiver(east, north, scale * btv_e, scale * btv_n,\n",
    "    #              angles='xy', scale_units='xy', scale=1, color='red')\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "def show_boat_arrows(ch, df, df_slice, dt_seconds=5, skip=2, current_scale=1):\n",
    "    delay = 16\n",
    "    dt = dt_seconds * G.SAMPLES_PER_SECOND\n",
    "    scale = dt_seconds\n",
    "    ss = slice(df_slice.start, df_slice.stop, dt)\n",
    "    dss = slice(ss.start+delay, ss.stop+delay, dt)\n",
    "    \n",
    "    mdf = df.loc[ss]\n",
    "    ddf = df.loc[dss]\n",
    "    vog_n = scale * ddf.sog * p.north_d(ddf.cog)\n",
    "    vog_e = scale * ddf.sog * p.east_d(ddf.cog)\n",
    "\n",
    "    tw_n = scale * ddf.tws * p.north_d(ddf.twd)\n",
    "    tw_e = scale * ddf.tws * p.east_d(ddf.twd)\n",
    "\n",
    "    hdg = mdf.hdg + df.variation.mean()\n",
    "    btv_n = scale * mdf.spd * p.north_d(hdg)\n",
    "    btv_e = scale * mdf.spd * p.east_d(hdg)\n",
    "\n",
    "    cur_n = current_scale * (np.asarray(vog_n) - np.asarray(btv_n))\n",
    "    cur_e = current_scale * (np.asarray(vog_e) - np.asarray(btv_e))\n",
    "\n",
    "    ch.mdf = mdf\n",
    "    ch.ddf = ddf\n",
    "    longitudes = np.asarray(mdf.longitude)\n",
    "    latitudes = np.asarray(mdf.latitude)\n",
    "    pos = np.vstack(G.MAP(longitudes, latitudes)).T \n",
    "\n",
    "    color = 'blue'\n",
    "    hwidth = scale/5\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, vog_e, vog_n), 0, None, skip):\n",
    "        avog = ch.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    color = 'green'\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, tw_e, tw_n), 0, None, skip):\n",
    "        atw = ch.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    color = 'red'\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, btv_e, btv_n), 0, None, skip):\n",
    "        abtv = ch.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    color = 'orange'\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, cur_e, cur_n), 0, None, skip):\n",
    "        acurrent = ch.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    ch.ax.legend([avog, atw, abtv, acurrent],\n",
    "                    'VOG TWD BTV CURRENT'.split(),\n",
    "                    loc='best')\n",
    "        \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "ch = chart.plot_chart(df, color='red')\n",
    "\n",
    "ll_mask = lor(lat_rho > ch.lat_max, lat_rho < ch.lat_min)\n",
    "ll_mask = lor(ll_mask, lon_rho > ch.lon_max, lon_rho < ch.lon_min)\n",
    "\n",
    "\n",
    "for time in [8, 9, 10]:\n",
    "    cscale = 1000 # 1000\n",
    "    u = cscale * current_e[time, :, :]\n",
    "    v = cscale * current_n[time, :, :]\n",
    "\n",
    "    wscale = 100 # 100\n",
    "    uwind = wscale * wind_e[time, :, :]\n",
    "    vwind = wscale * wind_n[time, :, :]\n",
    "    \n",
    "    mask = np.logical_not(lor(ll_mask, maske, maskn, u.mask, v.mask, uwind.mask, vwind.mask))\n",
    "    adt = arrow.get(to_datetime(ocean_time[time]))\n",
    "    display(adt.to('US/Pacific'))\n",
    "    \n",
    "    ch = chart.create_chart(ch)\n",
    "    ch.fig = plt.figure(figsize=(8, 10))\n",
    "    ch.ax = ch.fig.add_subplot(111)   \n",
    "    ch = chart.draw_chart(ch, ch.ax)\n",
    "    ch.ax.quiver(east[mask], north[mask], u[mask], v[mask], \n",
    "                angles='xy', scale_units='xy', scale=1, color='blue')\n",
    "    ch.ax.quiver(east[mask], north[mask], uwind[mask], vwind[mask], \n",
    "                angles='xy', scale_units='xy', scale=1, color='red')\n",
    "    ch.ax.set_title(model_file + \" : \" + str(adt.to('US/Pacific')))\n",
    "    ch.fig.tight_layout()\n",
    "\n",
    "    ch.fig.savefig(\"tide_\" + str(adt.to('US/Pacific'))+\".pdf\", orientation='portrait')\n",
    "\n",
    "print(np.array((v[mask].max(), v[mask].min()))/scale)\n",
    "print(scale)\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "time = 20\n",
    "if True:\n",
    "    u = scale * current_e[time, :, :]\n",
    "    v = scale * current_n[time, :, :]\n",
    "\n",
    "    mask = np.logical_not(lor(maske, maskn, u.mask, v.mask))\n",
    "    display(to_datetime(ocean_time[time]).isoformat())\n",
    "\n",
    "    \n",
    "ch = chart.create_chart(region)\n",
    "ch.fig = plt.figure(figsize=(8, 8))\n",
    "ch.ax = ch.fig.add_subplot(111)   \n",
    "ch = chart.draw_chart(ch, ch.ax)\n",
    "ch.ax.quiver(east[mask], north[mask], u[mask], v[mask], \n",
    "            angles='xy', scale_units='xy', scale=1, color='red')\n",
    "\n",
    "\n",
    "import itertools as it\n",
    "[(i, to_datetime(ot)) for i, ot in enumerate(ocean_time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "def show_boat_arrows(df, df_slice, dt_seconds=5, skip=2, current_scale=1):\n",
    "    delay = 16\n",
    "    dt = dt_seconds * G.SAMPLES_PER_SECOND\n",
    "    scale = dt_seconds\n",
    "    ss = slice(df_slice.start, df_slice.stop, dt)\n",
    "    dss = slice(ss.start+delay, ss.stop+delay, dt)\n",
    "    \n",
    "    mdf = df.loc[ss]\n",
    "    ddf = df.loc[dss]\n",
    "    vog_n = scale * ddf.sog * p.north_d(ddf.cog)\n",
    "    vog_e = scale * ddf.sog * p.east_d(ddf.cog)\n",
    "\n",
    "    tw_n = scale * ddf.tws * p.north_d(ddf.twd)\n",
    "    tw_e = scale * ddf.tws * p.east_d(ddf.twd)\n",
    "\n",
    "    hdg = mdf.hdg + df.variation.mean()\n",
    "    btv_n = scale * mdf.spd * p.north_d(hdg)\n",
    "    btv_e = scale * mdf.spd * p.east_d(hdg)\n",
    "\n",
    "    cur_n = current_scale * (np.asarray(vog_n) - np.asarray(btv_n))\n",
    "    cur_e = current_scale * (np.asarray(vog_e) - np.asarray(btv_e))\n",
    "\n",
    "    chart = plot_chart(mdf, 3, border=0.0)\n",
    "    chart.mdf = mdf\n",
    "    chart.ddf = ddf\n",
    "    longitudes = np.asarray(mdf.longitude)\n",
    "    latitudes = np.asarray(mdf.latitude)\n",
    "    pos = np.vstack(G.MAP(longitudes, latitudes)).T - (chart.west, chart.south)\n",
    "\n",
    "    color = 'blue'\n",
    "    hwidth = scale/5\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, vog_e, vog_n), 0, None, skip):\n",
    "        avog = chart.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    color = 'green'\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, tw_e, tw_n), 0, None, skip):\n",
    "        atw = chart.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    color = 'red'\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, btv_e, btv_n), 0, None, skip):\n",
    "        abtv = chart.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    color = 'orange'\n",
    "    for (east, north), ve, vn in it.islice(zip(pos, cur_e, cur_n), 0, None, skip):\n",
    "        acurrent = chart.ax.arrow(east, north, ve, vn, head_width=hwidth, length_includes_head=True, color=color)\n",
    "\n",
    "    chart.ax.legend([avog, atw, abtv, acurrent],\n",
    "                    'VOG TWD BTV CURRENT'.split(),\n",
    "                    loc='best')\n",
    "        \n",
    "    return chart\n"
   ]
  }
 ]
}