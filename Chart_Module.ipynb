{
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sail] *",
   "language": "python",
   "name": "conda-env-sail-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "timestamp": "2020-06-11T13:23:51.527281-07:00"
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charting and Graphing\n",
    "\n",
    "Collection of tools to create sailing charts, display race tracks, and plot instrument data.\n",
    "\n",
    "Most interesting part is the generation of GEO-registered charts, upon which lat/lon\n",
    "positions can be scale accurately ploted.\n",
    "\n",
    "Warning this is a [Literate Notebook](Literate_Notebook_Module.ipynb), i.e. the notebook contains the code for the charting module.  Do not edit the code in the module directly, edit the notebook and then regenerate the module code.\n",
    "\n",
    "    convert_notebook.py Chart_Module.ipynb --module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - let's start out with the goal in mind, and then work backwards\n",
    "\n",
    "def create_and_display_chart(race_data):\n",
    "    \"Load race data and then create a chart and draw the race track.\"\n",
    "    chart = plot_chart(race_data)\n",
    "    return chart\n",
    "\n",
    "def plot_instrument_data_from_race():\n",
    "    \"Load a race and plot several instruments on the same graph\"\n",
    "    df = example_race()\n",
    "    plot = quick_plot(df.row_times, \"df.spd df.sog df.tws\")\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Charting is critical to understanding the data collected during a race.  Data about SPD or AWA is disembodied without some sort of geographical reference.\n",
    "\n",
    "We think about physical space and situations, so we often as questions like \"did we pinch before the windward mark?\" or \"did we sail too far before jibing to the leeward mark?\".  These questions are tough to ask when only looking at graphs of heading and speed.  Knowing where we were and when is critical.\n",
    "\n",
    "\n",
    "![im](Data/Images/chart_chart_with_track.png)\n",
    "\n",
    "Key properties of a chart:\n",
    "\n",
    "- Accuracy: it should be based on accurate nautical data. Depths. Buoys. Etc.\n",
    "- Geolocation: the chart is an image which is measured in pixels, the race track is measured in GPS lat/lon.  We need to accurately place the track on the chart.  An image where the mapping from pixel coordinates to lat/lon is \"geolocated\".\n",
    "- Calibration: the map should be in familiar units, so that we can graph velocities in natural ways.  We use meters.\n",
    "\n",
    "After exploring many options, we converged on a NOAA charts (no surprise).  NOAA has a confusingly large number of chart options, including Raster Navigational Charts (RNC), Electronic Navigational Charts (ENC), and PDFs of the old paper charts.  To be honest, I'd use the PDFs if not for two problems:  i) the charts have annoying boundaries which are crossed by many races, and ii) the PDFs can be geolocated, but it is not trivial.  RNC files are geolocated, but they are in some sort of weird bespoke image format.  ENC is a vector based representation containing coastlines, buoys, and other navigational features as lat/lon coordinates.  ENCs are not images, and rendering ENCs to images is tricky, though it provides huge flexibility since you need not render any particular type of feature can be included, or removed.\n",
    "\n",
    "I have chosen to use the [NOAA tile representation](https://tileservice.charts.noaa.gov/tileset.html#50000_1-locator).\n",
    "\n",
    "### Additional Links\n",
    "\n",
    "- A web views for the NOAA tiles: [LINK](https://tileservice.charts.noaa.gov/tiles/50000_1/viewer-openlayers.html).\n",
    "- [NOAA Chart Navigator](https://www.charts.noaa.gov/InteractiveCatalog/nrnc.shtml): a map based navigator that will show you all the available charts.\n",
    "- [RNC vs ENC](https://nauticalcharts.noaa.gov/charts/rnc-and-enc-comparison.html): compare and contrast of RNC and ENC.  We use neither, though both would likely work with work.\n",
    "- [Chart Booklets](https://www.charts.noaa.gov/BookletChart/18449_BookletChart.pdf): a PDF booklet of small chart images at high resolution.  An area is divided into 18 pages, each on a different page.  Great for printing.  These are really cool and what I would use if I were using paper charts on my boat.\n",
    "\n",
    "### And more links\n",
    "\n",
    "- [mapzen](https://www.mapzen.com/) Pretty interesting high performance mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a tiled representation?\n",
    "\n",
    "Mapping web sites (like Google maps) use tile servers (more here [Wikipedia](https://en.wikipedia.org/wiki/Tiled_web_map)).  Also see this very cool [site](https://mc.bbbike.org/mc/?lon=-122.436&lat=47.661&zoom=14&num=4&mt0=mapnik&mt1=esri) that will allow you to compare **many** tiled maps (though it does **not** include NOAA charts, or any useful marine charts).\n",
    "\n",
    "NOAA tiled maps are great because they have stitched together every NOAA chart into a single world map (so we have no awkward chart boundaries).  Because these are actually mashups of the existing charts, the map is weird in the corners and away from the water.  You can see bits and pieces of different charts.  Luckily, the quality is high and consistent in the navigable waters.\n",
    "\n",
    "Large scale: a very odd looking (hand drawn?) map.  This is not useful!\n",
    "![im](Data/Images/chart_tile_big.png)\n",
    "\n",
    "Middle scale starts to look like a chart.\n",
    "![im](Data/Images/chart_tile_mid.png)\n",
    "\n",
    "You can keep drilling down to the finer scales (it stops where the highest resolution NOAA charts stop).\n",
    "![im](Data/Images/chart_tile_small.png)\n",
    "\n",
    "The beauty of using a tile server is that you can pull down just the tiles you need at the resolution you need (its never more than about 100 tiles).  For a while I considered using these services directly (like your web browser does when using google maps).  There are two issues.  1) Figuring out what tiles to load.  2) Remapping them them to a reasonable projection.\n",
    "\n",
    "Rather than query a web server to create every chart, we took an offline approach instead.\n",
    "\n",
    "1. Download a large MBTILES file that contans all the tiles for a region.\n",
    "  - MBTILES, defined by MapBox [spec](https://github.com/mapbox/mbtiles-spec), is an SQLite file containing all the tiles.\n",
    "  - The Pacific Northwest is MBTILES_06.  California is MBTILES_10.  Files are in `Data/MBTILES`\n",
    "  - Each of the files is very large, 500 Meg.\n",
    "2. From the MBTILES one can create a basemap that is very high res, that is focused on the sailable area in a region.\n",
    "  - Seattle map is 10,000 by 30,000 image.  130 Meg compressed TIF.\n",
    "  - This file is smaller than the MBTILES file, but not by a lot\n",
    "3. Either from MBTILES or basemap, extract the chart of interest that covers the extent of the race.\n",
    "4. To draw on this map, convert lat/lon into chart coordinates.\n",
    "\n",
    "Here is a quick link to a world map of MBTILE files [LINK](https://github.com/vokkim/noaa-nautical-charts) with helpful links to the actual files.\n",
    "\n",
    "![im](Data/Images/chart_mbtiles_map.png)\n",
    "\n",
    "And here is a low resolution version of a \"basemap\" for the Puget Sound.  Notice it does *NOT* include the San Juan Islands, it was purposely cropped to the Puget Sound south of Port Townsend.  This keeps it down to a manageable size.  The blank areas are not part of the NOAA charts, and are left undefined (a fancier approach would backfill these areas from another tile server... we don't care).\n",
    "\n",
    "![im](Data/Images/chart_basemap.jpg)\n",
    "\n",
    "Both the MBTILES file and the basemap are georegistered files.  They include metadata that describes the map projection, the geographic extent, and the scale.\n",
    "\n",
    "Why do it this way?  Couple of reasons.\n",
    "\n",
    "- Its faster than querying the web service, can run without an internet connection, and is perhaps more reliable.\n",
    "- We can use an extremely powerful tool called [GDAL](https://gdal.org/) to process the MBTILE to extract charts with arbitrary boundaries and scales, and convert to a local map projection that makes sense.\n",
    "- GDAL has python bindings, so we can use the same code to convert lat/lon to map coordinates.\n",
    "\n",
    "GDAL is the swiss army knife of GIS data.  In particular it is really good at dealing with reprojecting the data from one map projection to another (there are 100's of projections, [great site on projections](https://www.arcgis.com/apps/MapJournal/index.html?appid=31484c80dba54a058369dfb8e9ced549)).  GDAL is also very complex.  To get started, I recommend a set of introductory articles [A Gentle Introduction to GDAL](https://medium.com/planet-stories/a-gentle-introduction-to-gdal-part-1-a3253eb96082)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Reference Systems (SRS)\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Spatial_reference_system)\n",
    "\n",
    "In order to get GDAL to do its thing, you need to specify the various coordinate systems used in the map, etc.  This \"spatial reference system\" essentially defines the 3D position of any point on the map.  Converting between maps (with differnet SRS's) is then \"just math\".\n",
    "\n",
    "There are three coordinate systems of interest:\n",
    "\n",
    "1. The reference system of the MBTILES file. Luckily GDAL knows how to extract that information and silently and magically use it.\n",
    "  - The NOAA tiles are in \"[web mercator](https://en.wikipedia.org/wiki/Web_Mercator_projection)\".  [Mercator](https://en.wikipedia.org/wiki/Mercator_projection), as we learned in school stretches distance as you get near the poles.  And the \"web\" part introduces other inaccuracies for the sake of efficiency in browsers.\n",
    "2. The reference system of the charts we will generate.  Since web mercator is inaccurate, we use [transverse mercator](https://en.wikipedia.org/wiki/Transverse_Mercator_projection) centered near our region (which reduces distortion to less than a meter).\n",
    "3. The reference system for the GPS lat/lon measurements.  This is called WGS84.\n",
    "\n",
    "Note, there are several standard ways to specify SRS:\n",
    "\n",
    "- [EPSG](https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset).  This is a handy, huge table of standardized SRS's.\n",
    "  - Web mercator is : [EPSG:3857](https://epsg.io/3857)\n",
    "  - GPS coordinates: [EPSG:4326](https://epsg.io/4326)\n",
    "  - There is none for our bespoke transverse mercator.\n",
    "- [Proj4](https://proj.org/index.html):  *PROJ is a generic coordinate transformation software that transforms geospatial coordinates from one spatial reference system to another.*.  Proj provides a standard language for specifying SRS.\n",
    "  - Web mercator: `+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext  +no_defs`\n",
    "  - WGS84: `+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs `\n",
    "  - Transverse mercator centered in Seattle: `+proj=tmerc +lat_0=47.6873070 +lon_0=-122.4386440 +k_0=0.9996 +datum=WGS84 +units=m +no_defs`\n",
    "\n",
    "And there are others.  GDAL is the master of them all!  Below is the dump using `gdalinfo` on the MBTILES file.\n",
    "\n",
    "```\n",
    "> gdalinfo MBTILES_06.mbtiles\n",
    "Driver: MBTiles/MBTiles\n",
    "Files: MBTILES_06.mbtiles\n",
    "Size is 12582912, 4456448\n",
    "Coordinate System is:\n",
    "PROJCS[\"WGS 84 / Pseudo-Mercator\",\n",
    "    GEOGCS[\"WGS 84\",\n",
    "        DATUM[\"WGS_1984\",\n",
    "            SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "                AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "            AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "        PRIMEM[\"Greenwich\",0,\n",
    "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "        UNIT[\"degree\",0.0174532925199433,\n",
    "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "        AUTHORITY[\"EPSG\",\"4326\"]],\n",
    "    PROJECTION[\"Mercator_1SP\"],\n",
    "    PARAMETER[\"central_meridian\",0],\n",
    "    PARAMETER[\"scale_factor\",1],\n",
    "    PARAMETER[\"false_easting\",0],\n",
    "    PARAMETER[\"false_northing\",0],\n",
    "    UNIT[\"metre\",1,\n",
    "        AUTHORITY[\"EPSG\",\"9001\"]],\n",
    "    AXIS[\"X\",EAST],\n",
    "    AXIS[\"Y\",NORTH],\n",
    "    EXTENSION[\"PROJ4\",\"+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext  +no_defs\"],\n",
    "    AUTHORITY[\"EPSG\",\"3857\"]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map projections (very optional)\n",
    "\n",
    "The whole field of Geographic Information Systems (GIS) is pretty deep.  For example, what exactly is a DATUM?  How do you measure sea level?  How do you do it in Kansas, far from any ocean?  Is the globe a sphere, an ellipsoid, or some other strange shape?\n",
    "\n",
    "The reality is that most of the complexity comes from the fact that we've been building maps, and navigating for a very long time.  There are some awesome Web resources, where you can get lost for many hours (days).\n",
    "\n",
    "- [Measuring the Height of Mt. Everest](https://en.wikipedia.org/wiki/Great_Trigonometrical_Survey)\n",
    "- [US National Geodetic Survey](https://en.wikipedia.org/wiki/U.S._National_Geodetic_Survey).  Just keep reading and clicking.\n",
    "\n",
    "GPS really simplified things.  Where before you needed to using surveying equipment to measure the relative position of landmarks (in some cases over 1000's of miles), now one just uses GPS.  While handheld GPS is accurate to a few meters, by recording data over hours it can be accurate to inches.  Lot's of great info here: [GPS.gov](https://www.gps.gov/systems/gps/performance/accuracy/).\n",
    "\n",
    "GPS reports information in [WGS 84](https://en.wikipedia.org/wiki/World_Geodetic_System) which uses an ellipsoidal model of the earth's surface.  Maps, some of which were created many years ago, are a projection from a coordinate system used at the time (DATUM) to a flat piece of paper.  The map maker, and map users, want their map to have high accuracy for measuring distances and directions (like the direction of true north).  And you should be able to read off the lat/lon and use it to report locations, etc.\n",
    "\n",
    "But because there are maps made in many countries, for many reasons, and at many times in the past, GIS and GDAL needs to handle the various complex ways reference systems.\n",
    "\n",
    "For us GDAL handles two tricky tasks: i) creating a map which is geo-referenced, and ii) projecting lat/lon track points into the coordinates of the image.\n",
    "\n",
    "Note, I feel the whole field could benefit if you \"forgot\" all the niggling details from the past."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tile Servers\n",
    "\n",
    "As often happens, as I write I begin to understand better.  Writing a section naturally raises questions in my mind, and as I try to provide a link or reference I find additional info.  It happened again, as I wrote the section on tiled map servers.  To the rescue came the Open Street Map (OSM) page on [Slippy Maps](https://wiki.openstreetmap.org/wiki/Slippy_Map) (their funky name for tiled maps).  Specifically the referencing tiles is described [here](https://wiki.openstreetmap.org/wiki/Slippy_map_tilenames).\n",
    "\n",
    "For completeness, I'll include code to fetch maps from the NOAA server on demand.  This could work better if you do not know in advance where you'll be sailing, or if the file storage is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some libraries\n",
    "\n",
    "# Basics\n",
    "import os\n",
    "import math\n",
    "import time  # used to compute elapsed times\n",
    "\n",
    "# Matplotlib is the engine for plotting graphs and images\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.widgets as widgets\n",
    "import matplotlib.style as mplstyle\n",
    "# Try to make matplotlib faster.  See https://matplotlib.org/tutorials/introductory/usage.html#performance\n",
    "mplstyle.use('fast')\n",
    "\n",
    "# Numpy and Pandas are used to process our racing data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# OpenCV is a powerful tool for image manipulation.\n",
    "import cv2  # why is it called cv2?  ... just is.\n",
    "\n",
    "# These are libraries written for RegattaAnalysis\n",
    "from global_variables import G  # global variables\n",
    "from utils import DictClass, is_iterable\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - initial setup\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "# These are libraries written for RegattaAnalysis\n",
    "import race_logs                # load data from races\n",
    "import nbutils\n",
    "from nbutils import display_markdown, display\n",
    "\n",
    "# Initialize for Seattle.\n",
    "G.init_seattle(logging_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def new_axis(fignum=None, equal=False, clf=True):\n",
    "    \"Convenience to create an axis with optional CLF and EQUAL.\"\n",
    "    fig = plt.figure(fignum)\n",
    "    if clf:\n",
    "        fig.clf()\n",
    "    ax = fig.add_subplot(111)\n",
    "    if equal:\n",
    "        ax.axis('equal')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - in order to exercise charting code, we'll need to load a race\n",
    "\n",
    "def example_race(date=\"2019-11-16\"):\n",
    "    dfs, races, big_df = race_logs.read_dates([date], race_trim=False)\n",
    "    display(races)\n",
    "    return dfs[0]\n",
    "\n",
    "df = example_race()\n",
    "# df = example_race(\"2020-05-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "display_markdown(f\"### Some global constants related to chart preparation\")\n",
    "\n",
    "display_markdown(\"For any region, we first determine the center of the sailing area.\")\n",
    "display_markdown(f\"For {G.LOCALE} the center is **lat**: {G.LATITUDE_CENTER} **lon:** {G.LONGITUDE_CENTER}\")\n",
    "\n",
    "display_markdown(\"The Seattle local spatial reference system in Proj format\")\n",
    "display(G.PROJ4)\n",
    "\n",
    "display_markdown(\"Path to the MBTILES file:\")\n",
    "display(G.MBTILES_PATH)\n",
    "\n",
    "# In additon there is a direct python binding of GDAL that is available through pyproj\n",
    "import pyproj\n",
    "gmap = pyproj.Proj(G.PROJ4)\n",
    "\n",
    "space_needle = (-122.349254, 47.620367)  # (lon, lat) for GDAL and pyproj\n",
    "\n",
    "west, north = gmap(*space_needle)\n",
    "display_markdown(f\"The space needle is {west:.0f} meters east and {north:.0f} meters north of the center.\")\n",
    "\n",
    "display_markdown(\"We can also efficiently bulk convert lat/lon to meters. And then plot:\")\n",
    "df_west, df_north = gmap(np.array(df.longitude), np.array(df.latitude))\n",
    "\n",
    "# Matplotlib defaults to scaling each axis independently.  This fixes that.\n",
    "fig, ax = new_axis(equal=True)\n",
    "ax.plot(df_west, df_north)\n",
    "ax.set_title(\"Postion in meters from 'center of sailing area'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDAL: gdalwarp\n",
    "\n",
    "(I explored using the `pyproj` GDAL bindings to do this. The command line program `gdalwarp` ended up working well.  Long term should reinvestigate using pyproj directly.)\n",
    "\n",
    "Documentation from [gdalwarp](https://gdal.org/programs/gdalwarp.html) \n",
    "\n",
    "> The gdalwarp utility is an image mosaicing, reprojection and warping utility. The program can reproject to any supported projection, and can also apply GCPs stored with the image if the image is \u201craw\u201d with control information.\n",
    "\n",
    "`-t_srs <srs_def>`  Set target spatial reference.  *We use Proj4.*\n",
    "\n",
    "`-te <xmin ymin xmax ymax>`  Set georeferenced extents of output file to be created.  *We use the lat/lon boundaries.*\n",
    "\n",
    "`-te_srs <srs_def>` Specifies the SRS in which to interpret the coordinates given with -te. *We use lat/lon in WGS 84, aka GPS.*\n",
    "\n",
    "`-ts <width> <height>` Set output file size in pixels and lines. If width or height is set to 0, the other dimension will be guessed from the computed resolution.\n",
    "\n",
    "`-oo <NAME=VALUE>`  Dataset open option (format specific).  *We use this to specify the zoom level of the MBTILES file.*\n",
    "\n",
    "### Lat/Lon vs Lon/Lat\n",
    "\n",
    "A bit of an aside on lat/lon versus lon/lat.  I am prefer lat/lon.  GDAL uses lon/lat.\n",
    "Its a bug waiting to happen. We'll use named fields in a dict where we can.  And then\n",
    "only access GDAL through functions.  This should limit the risk.\n",
    "\n",
    "BTW, why dicts rather than classes?  Well classes are heavyweight and they clutter up my\n",
    "code.  It's actually work to get Python classes to do a lot more than dicts (for\n",
    "example, you can incorrectly set fields, etc).  I do like field access in classes much\n",
    "better: `foobar.field` is much better than `foobar['field']` (the second hurts my hands).\n",
    "\n",
    "The utils module has a cute hack called DictClass.  It's a class, but it behaves a lot\n",
    "like a dict.  We'll generally use DictClass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the heart of the chart extraction process.\n",
    "\n",
    "def gdal_extract_chart(chart, source_path, chart_path, zoom_level=None):\n",
    "    \"\"\"\n",
    "    Using GDAL, extract a chart from the source image.\n",
    "\n",
    "    chart                  : a dict with lat_max, lat_min, lon_max, lon_min, for the extent of the map\n",
    "    source_path, chart_path : path of the input and output files\n",
    "    zoom_level              : optional, specify to limit resolution and speed up (13 will do that)\n",
    "    pixels                  : max width/height of the image, other dimension is computed from extent\n",
    "    srs                     : spatial reference of the resulting chart\n",
    "    \"\"\"\n",
    "    # Find the extents of the map\n",
    "\n",
    "    sw = map_project(DictClass(lat=chart.lat_min, lon=chart.lon_min))  # Southwest corner\n",
    "    ne = map_project(DictClass(lat=chart.lat_max, lon=chart.lon_max))  # Northeast corner\n",
    "\n",
    "    south, west = sw.north, sw.east\n",
    "    north, east = ne.north, ne.east\n",
    "\n",
    "    # Setup gdalwarp args\n",
    "    # Define the extent of the chart in lon/lat\n",
    "    te = f\"-te {chart.lon_min:.7f} {chart.lat_min:.7f} {chart.lon_max:.7f} {chart.lat_max:.7f}\"\n",
    "    # Reference system of the extent\n",
    "    te_srs = \" -te_srs EPSG:4326 \"  # WGS 84\n",
    "\n",
    "    # Define the SRS of the result\n",
    "    t_srs = f\"-t_srs '{chart.proj}'\"\n",
    "    # Size the image to the longest axis,\n",
    "    if (east - west) > (north - south):  # wide?\n",
    "        ts = f\"-ts {chart.pixels} 0\"  # limit width\n",
    "    else:\n",
    "        ts = f\"-ts 0 {chart.pixels}\"   # limit height\n",
    "\n",
    "    # Note the default is to pick the zoom level that is matched to the output resolution.\n",
    "    # Smaller numbers are lower res, and faster.  13 will speed things up a bit.\n",
    "    if zoom_level is None:\n",
    "        zoom = \"\"\n",
    "    else:\n",
    "        zoom = f\"-oo ZOOM_LEVEL={zoom_level}\"  # A hint to determine the level of the pyramid to use.\n",
    "\n",
    "    command = f\"gdalwarp {zoom} {te} {te_srs} {t_srs} {ts} -r bilinear {source_path} {chart_path}\"\n",
    "\n",
    "    run_system_command(f\"rm {chart_path}\")  # remove output, since gdalwarp will not overwrite\n",
    "    run_system_command(command)\n",
    "    # Add the extent of the map in the projection\n",
    "    return chart.union(dict(south=south, north=north, east=east, west=west,\n",
    "                            path=chart_path, source=source_path))\n",
    "\n",
    "\n",
    "def run_system_command(command, dry_run=False):\n",
    "    \"Run a shell command, time it, and log.\"\n",
    "    G.logger.debug(f\"Running command: {command}\")\n",
    "    if not dry_run:\n",
    "        start = time.perf_counter()\n",
    "        os.system(command)\n",
    "        end = time.perf_counter()\n",
    "        G.logger.debug(f\"Command finished in {end-start:.3f} seconds.\")\n",
    "\n",
    "def map_project(p):\n",
    "    \"\"\"\n",
    "    Project lat/lon pair into our prefered map projection.\n",
    "    \"\"\"\n",
    "    east, north = G.MAP(p.lon, p.lat)  # gdal order is lon then lat, I prefer lat/lon\n",
    "    return DictClass(north=north, east=east)\n",
    "\n",
    "def extract_region(df, border=0.2, fudge = (0.015, -0.015)):\n",
    "    \"\"\"\n",
    "    Extract the geographic region which covers the entire race track.  BORDER is an\n",
    "    additional margin which ensures you do not bump up against the edge when graphing.\n",
    "    \"\"\"\n",
    "    # Add just a bit of \"fudge factor\" to ensure that the extent is not too small, which\n",
    "    # triggers some corner cases.\n",
    "\n",
    "    # TODO: since the border is applied in lat/lon separately, its is not uniform.  Same\n",
    "    # for FUDGE.\n",
    "    lat_max, lat_min = max_min_with_border(df.latitude, border) + fudge\n",
    "    lon_max, lon_min = max_min_with_border(df.longitude, border) + fudge\n",
    "\n",
    "    return DictClass(lat_max=lat_max, lat_min=lat_min,\n",
    "                     lon_max=lon_max, lon_min=lon_min)\n",
    "\n",
    "\n",
    "def max_min_with_border(values, border=0.1):\n",
    "    \"Return the range of a series, with a buffer added which is border times the range.\"\n",
    "    max = values.max()\n",
    "    min = values.min()\n",
    "    delta = (max - min)\n",
    "    max = max + border * delta\n",
    "    min = min - border * delta\n",
    "    return np.array((max, min))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - on performance\n",
    "\n",
    "# I started out thinking that extracting a basemap would make things go faster, but I\n",
    "# eventually realized the speed difference was due to the resolution of the data being\n",
    "# extracted.  The basemap is at level 14, which is a bit high for many of our races.\n",
    "\n",
    "# Currently extracting the \"correct\" resolution image directly from MBTILES files is\n",
    "# faster!  The main reason is that MBTILES contains all the resolutions, including the\n",
    "# lower res images.  Its faster to convert the lower res images.\n",
    "\n",
    "# Adding a border helps give context.\n",
    "\n",
    "G.set_logging_level(\"DEBUG\")\n",
    "\n",
    "region = extract_region(df, 0.2)\n",
    "display(region)\n",
    "\n",
    "# Setup for rendering a chart\n",
    "chart = region.union(dict(border=0.2, pixels=2000, proj=G.PROJ4))\n",
    "\n",
    "# Extract from the basemap\n",
    "chart = gdal_extract_chart(chart, G.BASE_MAP_PATH, '/tmp/base.tif')\n",
    "\n",
    "# Extract directly from MBTILES\n",
    "chart = gdal_extract_chart(chart, G.MBTILES_PATH, '/tmp/mbtile.tif')\n",
    "display(chart)\n",
    "\n",
    "# Note, for this test the time is close to identical (and very fast).  For larger extents,\n",
    "# MBTILES can be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basemap is not a clear winner.\n",
    "\n",
    "Glancing though the log output above, for this chart extracting directly from the full resolution MBtiles is actually a bit faster (it actually varies from chart to chart based on size).  \n",
    "\n",
    "The huge advantage is that you need not prepare a basemap (no pre-selecting a resolution or region)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook  - read the resulting image and display\n",
    "\n",
    "image = cv2.imread(chart.path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, ax = new_axis()\n",
    "\n",
    "# By specifying the extent, matplot \"knows\" the scale of the image.  Note, extent is\n",
    "# weird: (left, right, bottom, top) Let's set the image coordinates to start 0,0 at the\n",
    "# lower left.\n",
    "ax.imshow(image, extent=[0, chart.east - chart.west, 0, chart.north - chart.south])\n",
    "ax.grid(True)\n",
    "# We can plot the projected coordinates directly on the image.\n",
    "ax.plot(df_west - chart.west, df_north - chart.south)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfect, almost\n",
    "\n",
    "First take a moment to zoom in to the marina.  Keep drilling down until you can see the separate docks.  You can clearly see that we are at our dock in our slip, and that we back up to depart.\n",
    "\n",
    "This is close to perfect alignment.  Success.\n",
    "\n",
    "The overlayed track and the graph can be hard to see at points, particularly when zoomed in.  The issue is that the chart image uses bright and saturated colors, just as the track does.\n",
    "\n",
    "We can desaturate the image as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desaturate_image(im, factor=2):\n",
    "    \"Desaturate the colors in an image, in preparation for plotting on that image.\"\n",
    "    hsv = cv2.cvtColor(im, cv2.COLOR_RGB2HSV)  # HSV is hue, saturation, value (intensity)\n",
    "    hsv[:, :, 1] = hsv[:, :, 1] // factor      # divide the value by factor\n",
    "    val_offset = ((factor - 1) * 255) // factor\n",
    "    hsv[:, :, 2] = val_offset + (hsv[:, :, 2] // factor)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - use desaturated charts\n",
    "\n",
    "fig, ax = new_axis()\n",
    "\n",
    "ax.imshow(desaturate_image(image), extent=[0, chart.east - chart.west, 0, chart.north - chart.south])\n",
    "ax.grid(True)\n",
    "ax.plot(df_west - chart.west, df_north - chart.south)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all features.\n",
    "\n",
    "def plot_chart(df, fig=None, border=0.2, pixels=2000, color='green', fudge=(0.015, -0.015),  **plot_args):\n",
    "    \"\"\"\n",
    "    Plot a track for race.  The background chart comes from NOAA tiled charts.\n",
    "    \"\"\"\n",
    "    region = extract_region(df, border, fudge=fudge) \n",
    "    chart = create_chart(region, pixels=pixels)\n",
    "    chart.fig, chart.ax = create_figure(fig)\n",
    "    chart = draw_chart(chart, chart.ax)\n",
    "    chart = draw_track(df, chart, color=color, **plot_args)\n",
    "    return chart\n",
    "\n",
    "def create_chart(region, pixels=2000):\n",
    "    \"\"\"\n",
    "    Using the extent of the GPS race track, create a geolocated map image AND a\n",
    "    reprojection of the track into the local north/east coordinates.\n",
    "\n",
    "    Data is loaded into a 'chart' dict, which will collect info on this transformation and\n",
    "    later plots.\n",
    "    \"\"\"\n",
    "    # Extract the region of the race.\n",
    "    chart = region.union(dict(proj=G.PROJ4, pixels=pixels))\n",
    "    \n",
    "    chart = gdal_extract_chart(chart, G.MBTILES_PATH, \"/tmp/mbtile.tif\")\n",
    "    image = cv2.imread(chart.path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return chart.union(dict(image=image))\n",
    "\n",
    "def create_figure(fig=None, figsize=(6, 6)):\n",
    "    G.logger.debug(f\"Creating figure {fig}\")\n",
    "    if isinstance(fig, matplotlib.figure.Figure):\n",
    "        fig = fig\n",
    "    else:\n",
    "        fig = plt.figure(num=fig, figsize=figsize)\n",
    "    fig.clf()\n",
    "    ax = fig.add_subplot(111)   \n",
    "    return fig, ax\n",
    "\n",
    "def draw_chart(chart, ax=None):\n",
    "    if ax is None:\n",
    "        ax = chart.ax\n",
    "    ax.imshow(desaturate_image(chart.image), \n",
    "              extent=[chart.west, chart.east, chart.south, chart.north])\n",
    "    ax.grid(True)\n",
    "    return chart\n",
    "\n",
    "def draw_track(df, chart, ax=None, color='green', **plot_args):\n",
    "    \"\"\"\n",
    "    Convert the track from lat/lon to image coordinates and then draw.\n",
    "\n",
    "    Optionally draw on a specific axis.\n",
    "    \"\"\"\n",
    "    lon, lat = np.asarray(df.longitude), np.asarray(df.latitude)\n",
    "    track = np.vstack(G.MAP(lon, lat)).T\n",
    "    chart.track = track\n",
    "    if ax is None:\n",
    "        ax = chart.ax\n",
    "    chart.line = ax.plot(chart.track[:, 0], chart.track[:, 1], color=color, **plot_args)[0]\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - demonstrate that it works.\n",
    "\n",
    "ch = create_and_display_chart(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding race marks\n",
    "\n",
    "Returning to our original goal, we would like to understand boat performance at various points in the race.\n",
    "\n",
    "The graph above is from a race with a south wind, starting in front of the marina N, heading south to the B, and then north to R, and finally back to N.  Below are the mark descriptions from the Sloop Tavern Yacht Club [Race Book](https://www.styc.org/race_info/RaceBook/2020/2020.pdf) page 11.\n",
    "\n",
    "- N Round metal ball with flag located near the North end of Shilshole Breakwater (47\u00b0 41.064,\n",
    "  122 24.679), in 87 feet of water. This is the near old North Hamburger location.\n",
    "  O Temporary mark located North of Point Monroe, in approx. 90 feet of water (47\u00b0 42.600, 122 30.450).\n",
    "  \n",
    "- B Ballard Sails Buoy, a 3.5-ft. high White Buoy located Southwest of the Ship Canal entrance,\n",
    "  near the shore at Discovery Park (47\u00b0 40.285, 122\u00b025.342). This is the old South Hamburger\n",
    "  location.\n",
    "\n",
    "- R Spring Beach: A 3.5-ft. high White Buoy located in 40 ft. of water in the vicinity of Spring\n",
    "  Beach, approximately 2 nm N of Meadow Pt. (47\u00b0 44.387, 122 \u00b0 22.944 W). A railroad block\n",
    "  signal is located at Spring Beach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - graph the mark locations on the race track\n",
    "\n",
    "from latlonalt import LatLonAlt as lla\n",
    "\n",
    "styc_race_marks = dict(\n",
    "    n_mark = lla.from_degrees_minutes((47, 41.064), (-122, 24.679)),\n",
    "    b_mark = lla.from_degrees_minutes((47, 40.285), (-122, 25.342)),\n",
    "    r_mark = lla.from_degrees_minutes((47, 44.387), (-122, 22.944)),\n",
    "    u_mark = lla.from_degrees_minutes((47, 45.676), (-122, 23.833))\n",
    ")\n",
    "\n",
    "for key, val in styc_race_marks.items():\n",
    "    display_markdown(f\"The decimal degrees position of {key}: {val}\")\n",
    "\n",
    "lon = np.array([m.lon for m in styc_race_marks.values()])\n",
    "lat = np.array([m.lat for m in styc_race_marks.values()])\n",
    "\n",
    "# much like the code above to compute the track\n",
    "marks = np.vstack(G.MAP(lon, lat)).T \n",
    "\n",
    "# Add red x's to the chart ABOVE, at the location of the marks\n",
    "ch.ax.scatter(marks[:, 0], marks[:, 1], color='red', marker='x')\n",
    "              \n",
    "display_markdown(\"**Be sure to look at the chart above for the marks!**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Instruments\n",
    "\n",
    "Python, Pandas, and matplotlib are awesome at plotting data.  As we have shown in previous notebooks, it is relatively easy to produce high quality plots.\n",
    "\n",
    "The goal of this notebook is to align, or associate, instrument readings with the stages of the race.\n",
    "\n",
    "The conventional way to graph data is built into Pandas (see below):  There are several problems.\n",
    "\n",
    "- There is a lot of code to do just a bit of plotting.\n",
    "- When plotting instruments with different units (spd vs. hdg), it is handy to put them on different graphs.  These don't stay in sync (without additional work).\n",
    "- It is not clear how to align these plots with the map and marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - plot using conventional tools\n",
    "\n",
    "plt.figure()\n",
    "df.spd.plot()\n",
    "df.sog.plot()\n",
    "df.tws.plot()\n",
    "plt.grid()\n",
    "plt.legend(\"spd, sog, tws\".split(','), loc=\"upper right\")\n",
    "\n",
    "plt.figure()\n",
    "df.hdg.plot()\n",
    "df.twd.plot()\n",
    "df.awa.plot()\n",
    "plt.grid()\n",
    "plt.legend(\"hdg, twd, awa\".split(','), loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving and streamlining plotting\n",
    "\n",
    "The plan:\n",
    "\n",
    "- Create a quick one liner to plot instrument data with legends, etc.\n",
    "- Enable linking of plots, to examine instruments of varying types.\n",
    "- And finally, link this to the chart.\n",
    "  - Show only the portion of the track associated with the plot.\n",
    "  - A single click on the graph plots a marker on the track, to associate a point in time with a point in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quick_plot(index, data, legend=None, fignum=None, clf=True, title=None, s=slice(None, None, None), ylim=None):\n",
    "    \"\"\"\n",
    "    Super quick tool to display multiple plots on a single axis.\n",
    "\n",
    "    All data is assumed to share a single index (X axis).  All data is the same length.\n",
    "\n",
    "    INDEX, which can be None, is the common index for all plots.\n",
    "    DATA is a sequence of multiple Y axis data (e.g. list or numpy array)\n",
    "         NOTE: data can be string.  If so it is assumed that it is a comma separated list of\n",
    "         expressions (see example below).\n",
    "    LEGEND is a list of legend names one for each data\n",
    "    FIGNUM is the existing figure to use.\n",
    "    CLF to clear before plotting, or just plot on what is already there\n",
    "    YLIM to set the Y limits\n",
    "    S an optional slice to limit the data to display (or reduce the size)\n",
    "\n",
    "    For example: \n",
    "\n",
    "    quick_plot(df.index, (df.one, df.two, df.three), ['one', 'two', 'three'])\n",
    "    quick_plot(df.index, (df.one, df.two, df.three), \"df.one df.two df.three\")\n",
    "    quick_plot(df.index, \"df.one, df.two, df.three\")  # Spiffy all in one!\n",
    "    \"\"\"\n",
    "    # Setup the figure and axis\n",
    "    if isinstance(fignum, matplotlib.figure.Figure):\n",
    "        fig = fignum\n",
    "    else:\n",
    "        fig = plt.figure(num=fignum)\n",
    "    if clf:\n",
    "        fig.clf()\n",
    "    # Create a single axis that fills the figure\n",
    "    ax = fig.add_subplot(111)\n",
    "    # Do the plotting\n",
    "    plot = quick_plot_ax(ax, index, data, legend=legend, s=s)\n",
    "    # Decorate or adjust\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(*ylim)\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    fig.tight_layout()\n",
    "    return plot\n",
    "\n",
    "\n",
    "def quick_plot_ax(ax, index, data, legend=None, s=slice(None, None, None)):\n",
    "    \"Helper function.  See quick_plot for documentation of arguments.\"\n",
    "    if isinstance(data, str):\n",
    "        expressions = data.split(',')\n",
    "        data = []\n",
    "        for d in expressions:\n",
    "            G.logger.debug(f\"Evaluating expression {d}\")\n",
    "            data.append(eval(d))\n",
    "        if legend is None:\n",
    "            legend = expressions\n",
    "    np_data = [np.asarray(d) for d in data]\n",
    "    \n",
    "    def draw():\n",
    "        if index is None:\n",
    "            x = range(len(np_data[0][s]))\n",
    "        else:\n",
    "            x = index[s]\n",
    "        for d in np_data:\n",
    "            ax.plot(x, d[s])[0]\n",
    "        if is_datetime(index):\n",
    "            ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%H:%M', tz=G.TIMEZONE))\n",
    "        if isinstance(legend, str):\n",
    "            # When the loc is 'best' then it is very slow!\n",
    "            ax.legend(legend.split(','), loc='upper right')\n",
    "        elif is_iterable(legend):\n",
    "            ax.legend(legend, loc='upper right')\n",
    "        ax.grid(True)\n",
    "\n",
    "    def update_func(begin, end):\n",
    "        nonlocal s\n",
    "        s = slice(begin, end)\n",
    "        ax.clear()\n",
    "        draw()\n",
    "\n",
    "    def trim_func(*args):\n",
    "        pass\n",
    "\n",
    "    draw()\n",
    "\n",
    "    return DictClass(trim_func=trim_func, update_func=update_func)\n",
    "\n",
    "\n",
    "def is_datetime(series_like):\n",
    "    \"Does this series contain data which looks like a?\"\n",
    "    # The column types are weirdly obscure. Check the first value.\n",
    "    np_datetime = isinstance(nth_value(series_like, 0), np.datetime64)\n",
    "    pd_datetime = isinstance(nth_value(series_like, 0), pd.Timestamp)\n",
    "    return np_datetime or pd_datetime\n",
    "\n",
    "def nth_value(series_like, n):\n",
    "    if isinstance(series_like, pd.Series):\n",
    "        return series_like.iloc[n]\n",
    "    elif isinstance(series_like, np.ndarray):\n",
    "        return series_like[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook \n",
    "\n",
    "# Simple single graph.  \n",
    "quick_plot(df.row_times, \"df.spd, df.sog, df.tws\")\n",
    "\n",
    "# Compute a version of VMG (velocity made good)\n",
    "thdg = df.hdg + df.variation.mean()  # Get the boats heading in true north\n",
    "angle = np.radians(df.twd - thdg)    # Angle to the true wind\n",
    "vmg = np.abs(np.cos(angle)) * df.spd         # Speed in the direction of true wind.\n",
    "\n",
    "# Pair of linked graphs.\n",
    "fig = plt.figure(figsize=(8, 12))  # make this figure large\n",
    "ax1 = plt.subplot(211)             # Create two axes.\n",
    "ax2 = plt.subplot(212, sharex=ax1) # Link the x-axis of the axes.\n",
    "# Plot on each axis\n",
    "pl = quick_plot_ax(ax1, None, \"df.spd, df.sog, df.tws, vmg\")\n",
    "pl = quick_plot_ax(ax2, None, \"df.hdg, df.twd, 100+5*df.rudder, df.awa\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To link plot to the chart, we add two functions to the chart.  \n",
    "#\n",
    "# 1. to trim the track shown to match the plot.\n",
    "# 2. to show a point at a particular time\n",
    "\n",
    "def chart_update_functions(chart, skip=None):\n",
    "    \"\"\"\n",
    "    Create two update functions.\n",
    "    \n",
    "    trim_func(begin, end) redraws the track trimming off the points before begin and after\n",
    "    end.\n",
    "\n",
    "    point_func(time) draws mark at the particular time along the track\n",
    "    \"\"\"\n",
    "\n",
    "    # There can be a huge number of sampled points (at 10Hz).  This limits the total\n",
    "    # number of samples.\n",
    "    if skip is None:\n",
    "        skip = math.ceil(len(chart.track) / 8000)  # No more than 2000 points\n",
    "    track = chart.track[::skip]\n",
    "\n",
    "    def trim_func(begin, end):\n",
    "        G.logger.info(f\"trim_func {track.shape} {begin} {end}\")\n",
    "        begin = max(0, begin)\n",
    "        # end = min(track.shape[0])\n",
    "        G.logger.info(f\"trim_func {begin} {end}\")        \n",
    "        chart.begin, chart.end = begin, end\n",
    "        b, e = int(begin/skip), int(end/skip)\n",
    "        chart.line.set_data(track[b:e, 0],\n",
    "                            track[b:e, 1])\n",
    "        chart.fig.canvas.draw_idle()\n",
    "\n",
    "    chart.point = None\n",
    "\n",
    "    def point_func(time):\n",
    "        point = chart.track[time]\n",
    "        G.logger.info(f\"Calling point_func update with {time}, {point}\")\n",
    "        if chart.point is None:\n",
    "            chart.point = chart.ax.plot([point[0]], [point[1]], linestyle = 'None', marker='+', color='red')[0]\n",
    "        else:\n",
    "            chart.point.set_data([point[0]], [point[1]])\n",
    "        chart.fig.canvas.draw_idle()\n",
    "\n",
    "    chart.trim_func = trim_func\n",
    "    chart.point_func = point_func\n",
    "\n",
    "    return chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we pull it all together.\n",
    "\n",
    "def chart_and_plot(df, index, data, data2=None):\n",
    "    \"\"\"\n",
    "    Create a figure with one or two plots of data, along with a synced chart/track.\n",
    "\n",
    "    - If you zoom/pan the top plot, then the track will display the region of interest.\n",
    "    - If you click on either plot, then the point on the chart will be highlighted.\n",
    "    \"\"\"\n",
    "    if data2 is not None:\n",
    "        # Create three axes.\n",
    "        fig = plt.figure(figsize=(8, 10))  # make this figure large\n",
    "        ax1 = plt.subplot(311)\n",
    "        ax2 = plt.subplot(312, sharex=ax1)\n",
    "        ax_chart = plt.subplot(313)\n",
    "    else:\n",
    "        # Create two axes.\n",
    "        fig = plt.figure(figsize=(8, 8))  # make this figure large\n",
    "        ax1 = plt.subplot(211)\n",
    "        ax_chart = plt.subplot(212)\n",
    "        \n",
    "    quick_plot_ax(ax1, index, data)\n",
    "    if data2 is not None:\n",
    "        quick_plot_ax(ax2, index, data2)\n",
    "\n",
    "    # Chart in the third axis.\n",
    "    region = extract_region(df) \n",
    "    chart = create_chart(region)    \n",
    "    chart.fig = fig\n",
    "    chart.ax = ax_chart        # Assign the axis\n",
    "    chart = draw_chart(chart)\n",
    "    chart = draw_track(df, chart, color='chartreuse')  # Draw track in light color\n",
    "    chart = draw_track(df, chart, color='green')       # Draw again in darker\n",
    "    # Note, chart.line and other attributes are overridden, purposefully.\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Create a set of chart update functions, \n",
    "    chart = chart_update_functions(chart)\n",
    "\n",
    "    # Arrange it so that the plots match the chart, by redrawing the chart to highlight\n",
    "    # the currently zoomed region in the plots, stored in xlim\n",
    "\n",
    "    # Declare and register callbacks\n",
    "    def on_xlim_change(event_ax):\n",
    "        G.logger.info(f\"xlim changed\")\n",
    "        lo, hi = [int(v) for v in ax1.get_xlim()]\n",
    "        G.logger.info(f\"updated xlim: {(lo, hi)}\")\n",
    "        chart.trim_func(lo, hi)\n",
    "\n",
    "    ax1.callbacks.connect('xlim_changed', on_xlim_change)\n",
    "\n",
    "    def on_click(event):\n",
    "        G.logger.info(f\"Click event: {event.xdata}\")\n",
    "        if event.xdata is not None:\n",
    "            chart.point_func(int(event.xdata))\n",
    "\n",
    "    fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "    return chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "ch = chart_and_plot(df, None, \"df.spd, df.sog, df.tws, vmg\", \"df.hdg, df.twd, 100+5*df.rudder, df.awa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the critical tasks is to trim the data to remove time at the dock, or to slip into races.\n",
    "\n",
    "def trim_track(df, fig_or_num=None, border=0.2, skip=None, delay=0.01):\n",
    "    \"\"\"\n",
    "    Plot an interactive sail track on a map.  Provides sliders which can be used to trim\n",
    "    the begin and end of the track.\n",
    "\n",
    "    One potential use is to find the trim points so that only the race is\n",
    "    displayed/analyzed.\n",
    "\n",
    "    ch = plot_track(df)\n",
    "    # Play with the UI, this happens in a different thread\n",
    "    # At any point you can get the values of the sliders.\n",
    "    print(ch.begin, ch.end)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Chart in the third axis.\n",
    "    region = extract_region(df) \n",
    "    chart = create_chart(region)\n",
    "    chart.fig, chart.ax = create_figure(fig_or_num)\n",
    "\n",
    "    chart = draw_chart(chart)  \n",
    "    chart = draw_track(df, chart, color='chartreuse')  # Draw track in light color\n",
    "    chart = draw_track(df, chart, color='green')       # Draw again in darker   \n",
    "\n",
    "    # Chart overlapps the widgets... sometimes.\n",
    "    # chart.fig.tight_layout()\n",
    "\n",
    "    # Create a set of chart update functions, \n",
    "    chart = chart_update_functions(chart)\n",
    "\n",
    "    ax_beg = chart.fig.add_axes([0.05, 0.1, 0.03, 0.8], facecolor='lightgoldenrodyellow')\n",
    "    ax_end = chart.fig.add_axes([0.11, 0.1, 0.03, 0.8], facecolor='lightgoldenrodyellow')\n",
    "    count = chart.track.shape[0]\n",
    "    chart.begin, chart.end = 0, count-1\n",
    "    s_beg = widgets.Slider(ax_beg, 'Begin', 0, count, valinit=0, orientation='vertical', valfmt=\"%i\")\n",
    "    s_end = widgets.Slider(ax_end, 'End',   0, count-1, valinit=count-1, orientation='vertical', valfmt=\"%i\")\n",
    "\n",
    "    # Unfortunate \"bug\" that graph can be unresponsive if you do not keep a handle on the sliders.\n",
    "    # https://github.com/matplotlib/matplotlib/issues/3105/\n",
    "    chart.sliders = [s_beg, s_end]\n",
    "    chart.is_trimmed = False\n",
    "    chart = chart_update_functions(chart)\n",
    "\n",
    "    def trim(val):\n",
    "        G.logger.info(f\"Calling plot_track update.\")\n",
    "        chart.is_trimmed = True\n",
    "        chart.trim_func(int(s_beg.val), int(s_end.val))\n",
    "        chart.fig.canvas.draw_idle()\n",
    "\n",
    "    s_beg.on_changed(trim)\n",
    "    s_end.on_changed(trim)\n",
    "\n",
    "    return chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook \n",
    "\n",
    "ch = trim_track(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook\n",
    "\n",
    "# The trimming process runs asynchronously and in the background. When you're done, you can access the \n",
    "# result through the attributes begin and end\n",
    "\n",
    "start_time = df.iloc[ch.begin].row_times\n",
    "end_time = df.iloc[ch.end].row_times\n",
    "\n",
    "display_markdown(f\"Trimmed track starts at {start_time}.\")\n",
    "display_markdown(f\"Trimmed track starts at {end_time}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - Returning to tiles.  \n",
    "\n",
    "# This code is here for completeness.  It is not part of the module.  It can be substituted \n",
    "# for the offline code above if needed.\n",
    "#\n",
    "# The tiles are not geolocated in the same fashion as above.  Though this is not too hard.\n",
    "\n",
    "# For requesting tiles from the NOAA servers\n",
    "import requests\n",
    "import PIL\n",
    "import io\n",
    "import concurrent.futures\n",
    "\n",
    "TILE_SIZE = 256\n",
    "\n",
    "def fetch_noaa_chart(df, zoom=14, border=0.2):\n",
    "    # Add/sub just a bit to make the map interpretable for small excursions\n",
    "    start = time.perf_counter()\n",
    "    region = extract_region(df, border)    \n",
    "    \n",
    "    x_min, y_max = deg2num(region.lat_min, region.lon_min, zoom)  # South West corner\n",
    "    x_max, y_min = deg2num(region.lat_max, region.lon_max, zoom)  # North East corner\n",
    "    \n",
    "    # Add one to ensure we get the boundaries\n",
    "    x_max += 1\n",
    "    y_max += 1\n",
    "    \n",
    "    addresses = list(it.product(range(x_min, x_max), range(y_min, y_max), [zoom]))\n",
    "\n",
    "    G.logger.info(f\"About to fetch {len(addresses)} tiles.\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as ex:\n",
    "        addressed_tiles = list(ex.map(fetch_noaa_tile, addresses))\n",
    "    \n",
    "    cols = x_max - x_min\n",
    "    rows = y_max - y_min\n",
    "    res = np.zeros((rows * TILE_SIZE, cols * TILE_SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "    for (x, y, zoom), tile in addressed_tiles:\n",
    "        coffset = (x - x_min) * TILE_SIZE\n",
    "        roffset = (y - y_min) * TILE_SIZE\n",
    "        G.logger.debug(f\"{roffset}, {coffset}\")\n",
    "        res[roffset:(roffset+TILE_SIZE), coffset:(coffset+TILE_SIZE), :] = tile\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    G.logger.info(f\"Finished in {end-start:.3f} seconds.\")\n",
    "    return res\n",
    "\n",
    "def fetch_noaa_tile(address):\n",
    "    G.logger.debug(f\"Fetching tile: {address}\")\n",
    "    x, y, zoom = address\n",
    "    r = requests.get(noaa_url(x, y, zoom))\n",
    "    tile = PIL.Image.open(io.BytesIO(r.content))\n",
    "    if tile.mode != 'RGB':\n",
    "        np_tile = np.asarray(tile.convert(mode=\"RGB\"))\n",
    "    else:\n",
    "        np_tile = np.asarray(tile)\n",
    "    G.logger.debug(f\"Done fetching tile: {address}\")\n",
    "    return address, np_tile\n",
    "    \n",
    "def noaa_url(x, y, zoom):\n",
    "    return f\"https://tileservice.charts.noaa.gov/tiles/50000_1/{zoom}/{x}/{y}.png\"    \n",
    "\n",
    "def deg2num(lat_deg, lon_deg, zoom):\n",
    "    lat_rad = math.radians(lat_deg)\n",
    "    n = 2.0 ** zoom\n",
    "    xtile = int((lon_deg + 180.0) / 360.0 * n)\n",
    "    ytile = int((1.0 - math.asinh(math.tan(lat_rad)) / math.pi) / 2.0 * n)\n",
    "    return (xtile, ytile)\n",
    "\n",
    "def num2deg(xtile, ytile, zoom):\n",
    "    # This returns the NW-corner of the square. Use the function with xtile+1 and/or\n",
    "    # ytile+1 to get the other corners. With xtile+0.5 & ytile+0.5 it will return the\n",
    "    # center of the tile.\n",
    "    n = 2.0 ** zoom\n",
    "    lon_deg = xtile / n * 360.0 - 180.0\n",
    "    lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * ytile / n)))\n",
    "    lat_deg = math.degrees(lat_rad)\n",
    "    return (lat_deg, lon_deg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebook \n",
    "\n",
    "image = fetch_noaa_chart(df, zoom=14)\n",
    "\n",
    "fig, ax = new_axis()\n",
    "\n",
    "# By specifying the extent, matplot \"knows\" the scale of the image.  Note, extent is\n",
    "# weird: (left, right, bottom, top) Let's set the image coordinates to start 0,0 at the\n",
    "# lower left.\n",
    "ax.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook - This is here for historical reference...  we do not use basemaps anymore.\n",
    "\n",
    "#\n",
    "# This \"function\" includes calls to gdal_translate and gdaladdo, with a bit of documentation.\n",
    "#\n",
    "# Note it no longer works.\n",
    "\n",
    "def gdal_basemap(chart, source_path, chart_path, zoom_level=None):\n",
    "    \n",
    "    # Interesting part of this is that gdalwarp is used to generate a VRT file, and not\n",
    "    # the final image.  VRT is a language for specifying remaps.  No actual work is done.\n",
    "    zoom = \"-oo ZOOM_LEVEL=16\"\n",
    "    zoom = \"\"\n",
    "    command = \"gdalwarp\"\n",
    "    command += \" \" + zoom\n",
    "    command += \" \" + t_srs_arg\n",
    "    command += \" \" + te_arg\n",
    "    command += \" \" + f\"-te_srs EPSG:4326 -ts {map_width} 0 -r bilinear\"\n",
    "    command += \" \" + \"-of vrt\"\n",
    "    command += f\" {G.MBTILES_PATH} /tmp/chart.vrt\"\n",
    "\n",
    "    # The VRT file is read and executed by gdal_translate.  Why?  gdal_translate can\n",
    "    # produce compressed and tiled output.  And generally seems move powerful.\n",
    "    #\n",
    "    # The gdal_translate utility can be used to convert raster data between different\n",
    "    # formats, potentially performing some operations like subsettings, resampling, and\n",
    "    # rescaling pixels in the process.\n",
    "\n",
    "    command = \"gdal_translate\"\n",
    "    command += \" -co COMPRESS=JPEG -co TILED=YES\"\n",
    "    command += f\" /tmp/chart.vrt {G.BASE_MAP_PATH}\"\n",
    "\n",
    "    # The gdaladdo utility can be used to build or rebuild overview images for most\n",
    "    # supported file formats with one of several downsampling algorithms.\n",
    "    \n",
    "    command = \"gdaladdo --config COMPRESS_OVERVIEW JPEG --config INTERLEAVE_OVERVIEW PIXEL\"\n",
    "    command += \" -r average\"\n",
    "    command += f\" {G.BASE_MAP_PATH}\"\n",
    "    command += \" 2 4\"\n",
    "\n",
    "\n"
   ]
  }
 ]
}